El auge de la  inteligencia artificial  generativa ha despertado el temor de que pueda rebelarse. Numerosos expertos han advertido sobre los posibles peligros con el rápido avance de esta tecnología. Incluso los propios responsables de estas herramientas han contribuido a alimentar estas preocupaciones. Sam Altman, CEO de OpenAI, comparó su empresa con el Proyecto Manhattan. Una solución propuesta para abordar este problema ha sido la regulación. Sin embargo, las compañías líderes en esta revolución tecnológica, como Microsoft y OpenAI, estén abogando por la legislación.  En este contexto, OpenAI ha anunciado la creación de un nuevo equipo, liderado por Ilya Sutskever, científico jefe y cofundador de la empresa, que se encargará de desarrollar métodos para dirigir y controlar los sistemas de IA “superinteligentes”.  Sutskever, en colaboración con Jan Leike, miembro del equipo de alineación de OpenAI, advierte que en aproximadamente una década podría existir una IA con una inteligencia superior a la humana.  También destacan que esta IA no necesariamente sería benévola, por lo que OpenAI está trabajando en formas de regularla y restringirla. Reconocen que actualmente no tienen una solución para controlar una IA superinteligente y evitar su rebelión. Las técnicas actuales, como el aprendizaje por refuerzo a partir de la retroalimentación humana, dependen de la capacidad de supervisión de los humanos, pero no podrán supervisar de manera confiable sistemas de IA mucho más inteligentes que ellos. Este nuevo equipo de OpenAI, encabezado por los dos científicos mencionados, contará con el 20% de la capacidad de computación que la compañía ha adquirido hasta ahora.