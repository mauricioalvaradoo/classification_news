Investigadores de  Meta  y académicos externos han analizado la influencia de  Facebook  e  Instagram  en el comportamiento electoral de los usuarios, y han concluido en un primer estudio que los usuarios con tendencias ideológicas más conservadoras son los que habitualmente estaban expuestos a una mayor cantidad de ‘fake news’ en Facebook que los usuarios con opiniones más liberales. Esta investigación forma parte de una iniciativa de Meta anunciada a finales de agosto de 2020, el Estudio de elecciones de Facebook e Instagram (FIES), con el que se pretende conocer el impacto de las redes sociales durante los procesos electorales democráticos. Más concretamente, durante las elecciones presidenciales de Estados Unidos de ese mismo año. Para llevar a cabo estas investigaciones -de las que se espera publicar un total de 16, tal y como ha anunciado Meta-, la compañía dirigida de Mark Zuckerberg ha colaborado con 17 científicos externos y ajenos a la empresa,  “libres de decidir qué análisis ejecutar”  y teniendo  “la última palabra sobre el contenido de los trabajos de investigación” , tal y como explica Science en un comunicado. Esta colaboración comenzó después de que Meta estableciera contacto con los científicos a principios de 2020. En el caso de este medio, en el que se han publicado tres artículos,  cada estudio analizó la actividad de unos 23.000 usuarios en las redes sociales de Meta  entre finales de septiembre y finales de diciembre de ese año. La compañía tecnológica propiedad de Facebook e Instagram recopiló datos durante el ciclo electoral, previa autorización de los usuarios investigados, para enviarlos después a revistas académicas en formato de acceso público y gratuito para que estas pudiesen analizarlos. En el primer estudio publicado en la revista Science, ‘Assymetric Ideological Segregation in Exposure to Political News on Facebook’,  se define Facebook como un  “entorno social e informativo sustancialmente segregado ideológicamente”  y se destaca que esta segregación ideológica  “ se manifiesta mucho más en el contenido publicado por páginas y grupos que en el contenido publicado por amigos” . Más concretamente, los investigadores analizaron las noticias políticas que aparecían en los ‘feeds’ de los usuarios según sus tendencias políticas, esto es, si eran liberales o conservadores. Y llegaron a la conclusión de que  “hay una mayor prevalencia de contenido poco confiable en los medios de derechas con respecto a los de izquierdas” ,  de modo que los usuarios con tendencias más conservadoras están más expuestos en Facebok a información falsa o desinformación que las personas con ideas más liberales. En ‘How Do Social Media Feed Algorithms Affect Attitudes and Behavior in an Election Campaing?’, los científicos investigan la influencia de los algoritmos de Facebook e Instagram en los comportamientos electorales de los usuarios, a partir de usuarios con el muro de noticias cronológico y el muro de noticias impulsado por los algoritmos. Aquí, comentan que en el ‘feed’ cronológico de Facebook  “aumentó la proporción de contenido de fuentes no fiables en más de dos tercios en relación con el ‘feed’ algorítmico” , un incremento que también detectaron en Instagram, aunque en menor medida. Asimismo, los analistas han llegado a la conclusión de que este ‘feed’ cronológico fue capaz de reducir “drásticamente el tiempo que los usuarios pasaban” en ambas plataformas y su interacción en ellas, También “vieron más contenidos de amigos y de fuentes ideológicamente moderadas con audiencias mixtas; más contenido político, más contenido de fuentes no confiables; y menos contenido clasificado como contenido incívico”. El último de los estudios que publica Science -’Reshares on Social Media Amplify Political news but do not Detectably Affect Beliefs or Opinions’- se menciona que la función de republicar -compartir un contenido ya publicado por otra persona-contribuye a la popularización de determinadas publicaciones aunque esta acción no siempre desencadena la viralización un ‘post’. Así, han investigadola  cómo influye la eliminación de contenido compartido en Facebook en la actitud y el comportamiento político de los usuarios . Los científicos señalan que  “reduce sustancialmente la cantidad de noticias políticas, incluido el contenido de fuentes no confiables, a las que están expuestos los usuarios; disminuye los clics y las reacciones generales; y reduce los clics de noticias partidistas” . La eliminación de las publicaciones compartidas también reduce el conocimiento de los usuarios sobre las noticias, si bien no han detectado que afecte a la polarización política. Junto a los tres artículos publicados por Science, se añade una publicación de la revista Nature. Esta última se ha centrado en el análisis de las llamadas ‘cámaras de resonancia’, esto es, el fenómeno que se da tanto en medios de comunicación como en redes sociales en el que los participantes tienden a encontrar ideas que amplifican y refuerzan sus propias creencias. Los investigadores parten de la idea de que  la información que se ve en redes sociales  “puede ser más un reflejo”  de la identidad de los usuarios  “que una fuente de las opiniones”  que estos expresan . En este sentido, han concluido que cuando los usuarios vieron contenidos de fuentes afines en su ‘feed’,  “su tasa de participación fue más alta” y que “la mayoría del contenido que los usuarios adultos activos de Facebook en Estados Unidos ven en la plataforma que proviene de amigos políticamente afines” ; un contenido que “tiene el potencial de reforzar la identidad partidista, incluso si no es explícitamente político. Por otra parte, los investigadores han concluido que disminuir la cantidad de contenido con ideas afines durante los tres meses en los que se recopilaron los datos para estos estududios, redujo el compromiso de los usuarios, pero no cambió sus creencias o actitudes de forma significativa. La compañía tecnológica ha explicado, por su parte, que estos estudios  “podrían ayudar a responder las cuestiones más espinosas sobre las redes sociales y la democracia” , como ha expresado el presidente de Asuntos Globales de Meta, Nick Clegg. El directivo ha insistido en que estos análisis demuestran  “que hay poca evidencia de que las características clave de las plataformas de Meta por sí solas causen una polarización afectiva dañina o tengan efectos significativos en actitudes, creencias o comportamientos políticos clave” . Con ello, Clegg ha destacado que  “cuando los participantes en los experimentos vieron una cantidad reducida de contenido de fuentes que reforzaban sus puntos de vista, en realidad era más probable que se involucraran con el contenido de ideas afines que vieron” , lo que tampoco  “tuvo un impacto detectable en la polarización, las actitudes políticas o las creencias de los usuarios” . 
 Asimismo, ha matizado que, si bien la investigación publicada  “no resolverá todos los debates sobre las redes sociales y la democracia” , espera que estos estudios  “ayuden a la sociedad a comprender mejor estos temas” .