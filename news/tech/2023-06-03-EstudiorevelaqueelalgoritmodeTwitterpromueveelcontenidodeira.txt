El algoritmo de  Twitter  promueve tuits en el feed ‘Para ti’ que expresan contenido de ira y polarización afectiva, ocasionando un aumento de estos sentimientos en los usuarios e impactando “significativamente” en el discurso público, tal y como ha comprobado un estudio. Investigadores de las universidades de  Cornell y Berkeley  (ambas de Estados Unidos) han llevado a cabo un estudio sobre el  impacto de los algoritmos  de clasificación de las redes sociales y las implicaciones que tiene en la sociedad y en el compromiso democrático, en este caso enfocado en la plataforma de Elon Musk. Tal y como detallan, el objetivo de este estudio es comprender el papel “crucial” que tienen los algoritmos de aprendizaje automático que filtran y seleccionan contenido para los usuarios y, para ello, han recogido  1.731 respuestas a la encuesta de 806 participantes únicos de Estados Unidos , realizada en el mes de febrero de este año. Los investigadores  pudieron comprobar que el algoritmo de Twitter amplifica el contenido que despierta emociones , especialmente, recomienda el contenido de los ‘tuits’ que  expresan ira y animosidad fuera del grupo, así como polarización afectiva. Por otra parte, en cuanto a los tuits de carácter político, el algoritmo lleva a los lectores a percibir el grupo político al que son afines de forma más positiva y el grupo político externo de manera negativa. Sin embargo, a pesar de estas conclusiones, los investigadores también han comprobado que aunque los usuarios generalmente dicen preferir los tuits seleccionados por el algoritmo, en el caso de las  publicaciones de ámbito político  “es menos probable” que prefieran esta opción. De cara a obtener estos resultados, para cada participante se recopilaron dos conjuntos de tuits distintos. Por un lado, los diez primeros tuits personalizados generados por el algoritmo y, por otro lado, los diez primeros tuits con las publicaciones de las personas a las que siguen. Para evaluar el impacto de cada tuit,  los investigadores solicitaron a los participantes que evaluaran las emociones que veían reflejadas en la publicación  y las emociones que a ellos mismos les producía el tuit. De esta forma, pudieron evaluar si el algoritmo aplificaba el contenido emocional y si dicho contenido provocaba un aumento en las emociones del lector. Así, los participantes en el estudio evaluaban  emociones como la tristeza, ansiedad, felicidad y el enfado con escalas de hasta cuatro puntos,  desde “En absoluto” a “Extremadamente”. Como conclusión, la emoción que más se amplificó fue la ira. Tal y como muestra el estudio, se puede comprobar que los usuarios interaccionan más con el feed personalizado que con el cronológico, que muestra tuits de personas a las que siguen, tanto a la hora de dar ‘Me gusta’ como con los retuits, y el uso de fotografías y de enlaces en las publicaciones. Sin embargo,  también se registra que el algoritmo “no favorece necesariamente” a las cuentas más populares,  ya que las cuentas mostradas tienen un número medio de seguidores más bajo y es menos probable que estén verificadas. Tal y como se explica en el estudio, esto puede deberse a que las cuentas populares con más seguidores tienden a publicar ‘tuits’ con más frecuencia. Siguiendo esta línea, el estudio muestra resultados de cómo difieren los feeds de Twitter en términos de contenido político. Al respecto, se ha registrado que, tanto en el feed personalizado como en el cronológico,  alrededor del 20% de los tuits son de carácter político . Más concretamente, en ambos feeds se muestran aproximadamente el doble de publicaciones relacionadas con el grupo político al que el usuario es afín. Sin embargo, el algoritmo aumenta “ligeramente” la proporción de tuits de pertenencia externa al grupo político seguido por el usuario. Los investigadores también recabaron pruebas que demuestran que  los usuarios producen más contenido en base a lo que favorece el algoritmo.  Esto lo hacen a través de tres mecanismos, como el aprendizaje observacional, en el que los usuarios deducen que cuáles son las normas que aceptan el contenido favorecido por el algoritmo. Otro mecanismo es el aprendizaje por esfuerzo.  Esto se produce cuando un usuario ha sido recompensado con una mayor exposición por producir contenidos favorecidos por el algoritmo. Al verse más promocionado, produce más contenido similar en el futuro. Finalmente, los usuarios adoptan el mecanismo de la adaptación estratégica intencional, es decir, que modifican intencionadamente sus contenidos con el objetivo de obtener la mayor exposición según el algoritmo. En este sentido, al amplificar contenido emocional, partidista y de ira, los usuarios están creando más contenido relacionado con estas emociones, lo que según advierten los investigadores  “pueden ser indicativos de efectos mayores a largo plazo”.