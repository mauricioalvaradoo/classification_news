FraudGPT es el último ejemplo detectado que utiliza la tecnología de ‘chatbots’ basados en la  inteligencia artificial  (IA) generativa para incentivar la creación de ‘malware’ con una herramienta que se vende en foros de la Internet oscura (darkweb) y en Telegram. MIRA: El ‘chatbot’ de OpenAI, ChatGPT, puede utilizarse para crear ‘malware’ a partir de su función de apoyo para la escritura de código, y pese a los filtros de seguridad que sus responsables han implantado, como han demostrado investigaciones como las de Check Point y Forcepoint. Sin embargo,  la popularidad de la IA generativa y de los ‘chatbots’ ha supuesto la aparición de herramientas diseñadas específicamente para poner sus capacidades de programación al servicio de la creación de ‘malware ’, como ocurre con FraudGPT. Los investigadores de Netenrich han descubierto FraudGPT, una herramienta de IA que se distribuye en canales de Telegram desde el pasado 22 de julio y que se vende y promociona en la darkweb como “un bot sin limitaciones”. Con este ‘chatbot’, cualquier actor de amenazas puede crear código malicioso, páginas de ‘phishing’, o buscar vulnerabilidades y filtraciones, entre otros contenidos dañinos, de forma tan simple y sencilla como escribir unas indicaciones. Con ello, pueden personalizar campañas de ‘phishing’ para engañar a sus víctimas. Con anterioridad se ha detectado el caso de WormGPT, otra alternativa maliciosa a ChatGPT similar a FraudGPT que se lanzó el 13 de julio.