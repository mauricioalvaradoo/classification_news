OpenAI, Anthropic, Google y Microsoft se han unido para asegurar el desarrollo seguro y responsable de los denominados modelos de  inteligencia artificial  (IA) de frontera, para minimizar los potenciales riesgos que puedan suponer para el individuo y la sociedad. Frontier Model Forum nace con el objetivo de promover el desarrollo responsable de los modelos de frontera, los más sofisticados, que describen como aquellos “ modelos de aprendizaje automático a gran escala que superan las capacidades actualmente presentes en los modelos existentes más avanzados y pueden realizar una amplia variedad de tareas ”. Detrás de esta organización se encuentran las empresas más destacadas del panorama actual de la inteligencia artificial avanzada, OpenAI, Anthropic, Google y Microsoft. Las cuatro se comprometen a colaborar en el desarrollo seguro de estos modelos. Para ello, han establecido tres puntos sobre los que versará su actuación: avanzar en la investigación de la seguridad de la IA para minimizar sus potenciales riesgos, identificar las mejoras prácticas de seguridad para los modelos de frontera, y compartir sus conocimientos con los legisladores, los académicos y la sociedad civil. También se han propuesto apoyar el desarrollo de aplicaciones de esta tecnología que ayuden a abordar los mayores desafíos de la sociedad, como son la mitigación y adaptación al cambio climático, la detección y prevención tempranas del cáncer y la lucha contra las ciberamenazas. Establecerán, además, en los próximos meses un Consejo asesor que ayudará a guiar la estrategia y prioridades de los integrantes de esta organización profesional, como informan en una nota de prensa conjunta.