OpenAI  ha lanzado una herramienta para averiguar y explicar el funcionamiento interno de los modelos de lenguaje grandes (LLM) en la  Inteligencia Artificial  ( IA ), que utiliza GPT-4 para analizar los modelos, explicarlos y anticipar cuáles serán los posibles problemas con los sistemas de IA. Los modelos de lenguaje en el ámbito de la IA, como por ejemplo GPT de OpenAI, llegan a conclusiones y producen resultados sorprendentes de forma independiente, por lo que cada vez se implementan en más ámbitos y situaciones del día a día, aprendiendo más y volviéndose más inteligentes. Sin embargo, la comprensión humana de cómo funcionan internamente estos modelos de lenguaje es limitada.  Es difícil conocer con certeza por qué un modelo responde de la forma en la que lo hace para cada situación . También es complicado averiguar cómo aumentan su conocimiento, si lo hacen de forma sesgada o si utilizan el engaño. De cara a comprender mejor el funcionamiento de los LLM, OpenAI ha lanzado una herramienta con la que se podrá analizar qué partes del modelo son responsables de cada función y de sus comportamientos. Esta herramienta, según explica OpenAI en un comunicado en su web, se basa en un proceso automatizado que utiliza el modelo de lenguaje GPT-4 para  “producir y puntuar explicaciones en lenguaje natural del comportamiento de las neuronas”  de un LLM en concreto, en este caso GPT-2 y, posteriormente, aplicarlo a las neuronas en otro modelo de lenguaje. Los modelos LLM están conformados por neuronas que identifican patrones específicos en el texto que introduce el usuario para poder generar una respuesta en consecuencia. Teniendo esto en cuenta, la herramienta de OpenAI divide el modelo de GPT-2 en distintas piezas y realiza un proceso de tres pasos. En primer lugar, se genera una explicación sobre un tema mostrando secuencias de texto relevantes en el modelo que se está evaluando, en este caso GPT-2. En base a ello, la herramienta analiza cada vez que una  “neurona”  se activa. Después,  se enseña todo ello al modelo GPT-4  que, con esta información, genera una explicación y una predicción sobre cómo se comportaría la neurona según el caso. Por último, la herramienta de OpenAI utiliza de nuevo GPT-4 para comparar el comportamiento de la neurona simulada en el segundo paso y la neurona real de GPT-2. Además, esta herramienta puntúa la comparación de ambas neuronas, detallando cómo coincide la explicación de GPT-4 con el comportamiento real del LLM evaluado, como explica la compañía. Con todo ello, según ha señalado uno de los responsables del proyecto, William Sanders, en declaraciones a TechCrunch, la compañía pretende desarrollar  “formas de anticipar cuáles serán los problemas con un sistema de IA” . Es decir, conocer mejor su funcionamiento interno para poder saber si se ha de confiar en los resultados del modelo y en las respuestas que crea. Aunque esta herramienta se encuentra en una fase preliminar, los investigadores han podido generar explicaciones para las 307.200 neuronas en GPT-2, y las han compilado en un conjunto de datos que se ha publicó junto con el código de la herramienta en GitHub. Entre sus funciones,  se podrá mejorar el rendimiento de los modelos de lenguaje , así como identificar situaciones como el uso de un sesgo en su comportamiento. No obstante, aún está en pruebas y, por tanto, se conocerán más utilidades en el futuro.