Microsoft  es la empresa que ha construido un superordenador capaz de entrenar el modelo de lenguaje gran tamaño de  OpenAI , conocido como GPT, un proyecto que ha contado con una inversión de varios cientos de millones de dólares y cuyas innovaciones la compañía tecnológica pone a disposición tanto de sus servicios como de sus clientes. Microsoft comenzó a trabajar en nuevas capacidades de computación en Azure en 2019, cuando inició una colaboración con OpenAI. El objetivo era entrenar modelos de gran tamaño para acelerar el avance de la inteligencia artificial (IA), y, de hecho, el superordenador IA de Azure ha entrenado el modelo de lenguaje, conocido por potenciar el chatbot ChatGPT. La infraestructura de computación en la nube creada empleaba decenas de miles de unidades gráficas de Nvidia A100 optimizadas para IA conectadas entre sí formando “ una red de de alto rendimiento y baja latencia ”, y comunicadas mediante la arquitectura InfiniBand, también de Nvidia. “Esta escala es mayor que la que han probado incluso los proveedores de GPU y equipos de red”, ha apuntado el jefe de producto de Microsoft para Azure High, Nidhi Chappell. “ Era un territorio desconocido. Nadie sabía con seguridad si el hardware podía llevarse tan lejos sin romperse ”, añade. Para poder entrenar un modelo de ese tamaño dividieron la carga de trabajo de computación en miles de GPU alojadas en un clúster. Chappell explica en la web de noticias de Microsoft que no se trataba solo de conectar una gran cantidad de GPU y ponerlas a trabajar juntas, sino que “ hay mucha optimización a nivel de sistema para obtener el mejor rendimiento ”. El desarrollo de este proyecto ha supuesto una inversión de varios cientos de millones de dólares, según ha trasladado el vicepresidente ejecutivo de Microsoft que supervisa la nube y la IA, Scott Guthrie, a Bloomberg. Fruto de estos trabajos, Microsoft ha anunciado este lunes nuevas máquinas virtuales que integran las últimas GPU Nividia H100 Tensor Core y la red Quantum-2 InfiniBand, como ha informado el director principal de productos, Azure HPC+AI, Matt Vegas. Se trata de la VM ND H100 v5, que admite tamaños de entre ocho y miles de GPU y está disponible en una versión preliminar, aunque Microsoft pretende convertirlo “ en una oferta estándar de Azure ” para que cualquiera pueda “ desbloquear el potencial de la IA a escala en la nube ”. Por otra parte, los avances en el modelo de lenguaje OpenAI se han implementado también en los servicios de Microsoft, como en el nuevo Bing; en GitHub Copilot, que ofrece sugerencias para desarrollar código; o en Azure OpenAI Service, por ejemplo. Se espera que en los próximos días se presente la nueva generación de GPT.