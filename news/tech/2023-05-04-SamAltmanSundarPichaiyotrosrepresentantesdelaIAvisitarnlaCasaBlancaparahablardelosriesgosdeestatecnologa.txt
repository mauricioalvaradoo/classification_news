La Casa Blanca invitó a directivos de empresas avanzadas en  inteligencia artificial  (IA), como Google, Microsoft, OpenAI y Anthropic,para acudir el jueves a una discusión sobre “los riesgos” asociados a esta tecnología con varios miembros del Gobierno, entre ellos la vicepresidenta Kamala Harris.  “Nuestro objetivo es tener una  discusión franca sobre los riesgos actuales  y a corto plazo que percibimos en los desarrollos de IA” , dice la invitación conocida por la AFP el martes.  El gobierno también busca discutir  “pasos para reducir esos riesgos,  y otras maneras en que podemos trabajar juntos para asegurarnos de que los estadounidenses se benefician de los avances de la IA mientras están protegidos de peligros.”   Satya Nadella  (Microsoft),  Sundar Pichai  (Google),  Sam Altman  (OpenAI) y  Dario Amodei  (Anthropic) confirmaron su participación, según la Casa Blanca.  La inteligencia artificial ha estado presente en la vida cotidiana durante años, desde los algoritmos de recomendación de las redes sociales hasta los electrodomésticos de alta gama. Sin embargo, el deslumbrante éxito desde fines del año pasado de  ChatGPT,  la interfaz de IA generativa de OpenAI, una empresa emergente financiada ampliamente por Microsoft, fue el  punto de partida para una carrera hacia sistemas cada vez más intuitivos y eficientes , que son capaces de generar textos, imágenes y códigos de programación cada vez más complejo.  Su lanzamiento despertó entusiasmo e inquietudes a una nueva escala. Especialmente cuando Sam Altman, el director de OpenAI, anticipó la próxima generación de la llamada IA “general”, donde los programas serán “más inteligentes que los humanos en general”.  Los riesgos de la IA van desde la  discriminación por algoritmos hasta la automatización de tareas realizadas por humanos , el robo de propiedad intelectual o la desinformación sofisticada a gran escala, entre otros.  “Los modelos de lenguaje capaces de generar imágenes, sonido y video son un sueño hecho realidad para quienes quieren destruir las democracias” , advirtió el profesor de UC Berkeley, David Harris, especialista en políticas públicas e IA.  A fines de 2022, la Casa Blanca publicó un “Plan para una Declaración de Derechos de la IA”, un breve documento que enumera principios generales como la protección contra sistemas peligrosos o falibles.  A principios de este año, el Instituto Nacional de Estándares y Tecnología (NIST), un centro afiliado al gobierno, diseñó un “marco para la gestión de riesgos” relacionado con la IA. El presidente Biden dijo el mes pasado que estas empresas  “claramente (...) deben asegurarse de que  sus productos sean seguros antes de ponerlos a disposición del público en general” ,  dice la invitación.  Sin embargo,  “estas directrices y declaraciones no obligan a las empresas afectadas a hacer nada”,  subrayo David Harris, quien fue director de investigación en IA en Meta.  Los gigantes de la IA no niegan que existan riesgos , pero temen que se asfixie la innovación por leyes demasiado restrictivas.  “Estoy seguro de que la IA será utilizada por  actores maliciosos , y sí, va a causar daños” , dijo el miércoles el economista jefe de Microsoft, Michael Schwarz, durante un panel en el Foro Económico Mundial de Ginebra, según Bloomberg. Pero pidió a los legisladores que no se apresuren y que cuando haya un “daño real”, se aseguren de que   “los beneficios de la regulación sean mayores que el precio para la sociedad”. “La última vez que nos enfrentamos a semejante convulsión social debido a las tecnologías fue a comienzos de la web 2.0, en los años 2002″ , dijo el miércoles Lina Khan, presidenta de la Comisión Federal de Comercio, la agencia estadounidense de protección al consumidor.  Al otro lado del Atlántico, Europa espera liderar de nuevo el camino hacia una regulación ad-hoc en torno a la IA, como ya los hizo con la ley de datos personales.