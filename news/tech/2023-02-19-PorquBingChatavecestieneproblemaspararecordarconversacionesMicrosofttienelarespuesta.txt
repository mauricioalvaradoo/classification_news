El reciente chatbot conversacional de  Microsoft , Bing Chat, ha mostrado tener algunos problemas para recordar conversaciones. Algunos usuarios han reportado que esta tecnología se ha mostrado “decepcionado y frustrado”. Como se sabe, la compañía liderada por Bill Gates acaba de lanzar una versión renovada del buscador y es  capaz de entablar conversaciones, responder con naturalidad  e incluso mostrar interés por las conversaciones. Sn embargo, de acuerdo con algunos usuarios en Twitter , este “perdería los papeles” por momentos.  “Pero, ¿cómo que no dice nada? ¿No has leído el párrafo que te copiado antes? ¿No lo ves en el artículo?  ¿Estás ciego o qué?” ,  respondió la IA a un usuario en dicha red social. Aunque no se ha comprobado la autenticidad de las capturas, la “frustración” de la IA es bastante notoria. Al respecto,  Microsoft ha brindado las razones por las cuales esta tecnología se estaría comportando así.  “Las  sesiones de chat muy largas pueden confundir al modelo  sobre qué preguntas está respondiendo y, por lo tanto, creemos que es posible que debamos agregar una herramienta para que pueda actualizar el contexto más fácilmente o comenzar desde cero” , expresó la compañía mediante su  blog. Microsoft también dijo haber descubierto que luego de 15 o más preguntas, Bing Chat   “puede volverse repetitivo o puede ser incitado/provocado a dar respuestas que no son necesariamente útiles” . El comportamiento no responde al tono con el que fue diseñado, agregaron. Como se sabe,  el nuevo chatbot aún está en etapa de prueba  a cargo de Satya Nadella, quien es clave para el desarrollo de la IA gracias a los comentarios de los usuarios.