Ya no es divertido. La  inteligencia artificial  (IA) ha tenido un crecimiento importante en el último año. Todos hablan de ella, la usan y experimentan. Quienes también la usan son los ciberdelincuentes para alterar fotos y videos publicados en redes sociales como  Instagram . Se trata de la sextorsión, una actividad delictiva que consiste en usar imágenes sexuales para exigir dinero a su víctima a cambio de no publicarlas, de hacerlas viral. Ahora no importa si son reales. Con la inteligencia artificial han conseguido crear falsas imágenes. Incluso el FBI ha alertado en un informe sobre esta nueva forma de ataque usando la inteligencia artificial, señala la página El Español. “El FBI advierte al público sobre actores maliciosos que crean contenido sintético (comúnmente conocido como deepfakes) mediante la manipulación de fotografías o videos benignos para atacar a las víctimas”, señala el reporte del FBI. Muchas víctimas de esta estafa no saben que sus imágenes fueron copiadas, manipuladas y distribuidas. Entre los afectados se incluyen a los menores de edad. Luego, el ciberdelincuente hace contacto con la víctima. Para el FBI se ha detectado dos movimientos: primero, el agresor puede exigir dinero a cambio de no publicar las imágenes o vídeos con familiares y amigos, o lo que puede hacer es exigir que la víctima les enviara imágenes o videos reales de temática sexual. Es poco lo que se puede hacer una vez se cae en las garras de estos delincuentes. El FBI recomienda tener cuidado al publicar en redes sociales o enviar mensajes con fotos personales, videos e información de identificación. Además, es preferible no negociar con estos facinerosos y lo mejor es acudir a las autoridades.