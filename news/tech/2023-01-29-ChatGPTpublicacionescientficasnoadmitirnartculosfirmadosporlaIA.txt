Springer Nature ha prohibido los artículos escritos con herramientas de lenguaje como  ChatGPT  en sus publicaciones científicas cuando estén identificada como autoras por entender que una inteligencia artificial (IA) no puede asumir la responsabilidad por el trabajo. ChatGPT  de OpenAI ha sorprendido por su  capacidad para redactar textos de forma que no sea posible, o al menos muy difícil, detectar que no son obra de una persona.  Esto ha generado preocupación en ámbitos como el científico sobre el uso ético de esta herramienta y otros modelos de lenguaje extenso (LLM, en inglés) similares. “La gran preocupación en la comunidad de investigación es que los estudiantes y los científicos puedan  hacer pasar engañosamente el texto escrito por el LLM como propio , o usar los LLM de manera simplista (como para realizar una revisión bibliográfica incompleta) y producir un trabajo que no sea confiable” , explican el grupo editor Springer Nature en un editorial. Esta situación le ha llevado a  actualizar las directrices para la publicación de investigaciones en revistas  como Nature, en busca de una mayor transparencia y veracidad en los artículos. Por ello no aceptarán publicaciones en las que un modelo de lenguaje como  ChatGPT  aparezca identificado como autor, porque  “cualquier atribución de autoría conlleva responsabilidad por el trabajo, y las herramientas de IA no pueden asumir tal responsabilidad”. Tampoco aceptarán los trabajos que hayan usado una de estas herramientas como apoyo para la documentación,  pero no lo hayan indicado en las secciones de métodos o agradecimientos, aunque también admiten que se indique en la introducción  “u otra sección apropiada”.