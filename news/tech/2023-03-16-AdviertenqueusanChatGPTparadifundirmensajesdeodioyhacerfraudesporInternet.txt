La extensión del uso de  ChatGPT , uno de los últimos desarrollos de inteligencia artificial (IA) generativa que se ha puesto a disposición del público, conlleva ventajas en materia de seguridad como la automatización de tareas rutinarias o la creación de chatbots amables, pero también puede acarrear riesgos como el uso de esta tecnología para la difusión de mensajes de odio o para realizar fraudes por internet como el phishing. Así se desprende de un análisis realizado por Prosegur Research, el foro de reflexión y análisis de la compañía, en el que se analizan las implicaciones de ChatGPT desde la perspectiva de la seguridad e identifica los principales riesgos y oportunidades que se abren con su aplicación a diferentes ámbitos. La polarización social es uno de los diez riesgos que ha detectado el estudio de Prosegur Research, que explica que, debido a la capacidad de las inteligencias artificiales generativas de producir contenidos multimedia, pueden ser utilizadas para difundir mensajes de odio o discriminación, así como mensajes de carácter radical o extremista. El phishing, o generación automatizada de correos de apariencia real con objeto de engañar a usuarios a efectos de acceder a información confidencial o a los sistemas informáticos, es otro de los riesgos que entraña esta tecnología, ya que su escritura de alta calidad no levanta sospechas. La generación de noticias falsas, “ una cuestión que afecta a la seguridad nacional dañando la cohesión social y los principios democráticos ”, es otro de los puntos que destaca Prosegur, que ve en el ‘doxing’, o difusión de bulos para dañar la credibilidad de organizaciones, otro de los puntos negativos de esta IA. La posible fuga de información o robo de datos, las estafas y fraudes “ de calidad ” y la generación de chatbots maliciosos con el objetivo de obtener información sensible o alcanzar fines ilícitos económicos también se encuentran en la cara oscura de esta tecnología. Prosegur advierte también de las suplantaciones de identidad a través de las ‘deep fakes’ y de la capacidad de esta IA para generar textos, imágenes y vídeos y para simular la voz; la generación de códigos maliciosos o el uso de esta nueva tecnología en la lucha de poder geopolítico y geoeconómico, ya que “ los datos y las tecnologías están en el centro de configuración del poder ”. No obstante, normalmente esta tecnología no nace orientada hacia un uso malicioso y puede generar oportunidades en el campo de la seguridad, como la automatización de tareas rutinarias en funciones de seguridad, lo que facilita el bienestar de los empleados al eliminar tareas repetitivas y tediosas, según el informe. Al igual que hay riesgo de generar chatbots maliciosos --añade--, existen otros de carácter “atractivo”, que gozan de un perfil más amable y humano y que mejoran la interacción con clientes y otras personas. Esta IA permite el acceso a ingentes cantidades de información de interés para la seguridad de una manera estructurada por el uso del lenguaje natural potenciando las capacidades de inteligencia de fuentes abiertas (OSINT) y, según la compañía, puede ser positiva en el análisis de riesgos y en el ámbito del reconocimiento de patrones y anomalías. En materia de inteligencia, Prosegur asegura que ChatGPT puede contribuir a la generación de hipótesis, la identificación de tendencias y la construcción de escenarios, y en el ámbito de las recomendaciones  “no sustituye de ninguna manera la labor de un analista de seguridad internacional pero apoya algunas tareas ”. Es de ayuda en la analítica predictiva al facilitar ciertas predicciones con sus probabilidades asociadas en base a la ingente cantidad de datos en los que se basa al tiempo que ayuda a la detección de ‘phishing’ y a identificar vulnerabilidades o generar contraseñas seguras. Las inteligencias artificiales generativas tienen también una vertiente de aprendizaje, según señala el estudio, ya que pueden ser un primer punto para el aprendizaje sobre cuestiones vinculadas a seguridad, tecnologías o riesgos.