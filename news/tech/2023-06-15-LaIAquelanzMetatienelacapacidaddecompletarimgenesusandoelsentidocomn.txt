Meta ha presentado una  inteligencia artificial  que puede completar imágenes utilizando el “sentido común”. El modelo de la compañía no compara los píxeles como otras herramientas del rubro, sino que comprende representaciones abstractas a partir de “conocimiento previo sobre el mundo”. Mediante una publicación en su  blog , Meta anunció el lanzamiento de esta nueva herramienta a la cual han llamado Image  Joint Embedding Predictive Architecture (I-JEPA).  El modelo está basado en la visión del científico Yann LeCun, jefe de IA de la compañía de Mark Zuckerberg. “Su visión es  crear máquinas que puedan aprender modelos internos de cómo funciona el mundo para que puedan aprender mucho más rápido , planificar cómo realizar tareas complejas y adaptarse fácilmente a situaciones desconocidas” , agrega. El modelo I-JEPA utiliza el método de aprendizaje “autosupervisado” , es decir, analizó directamente imágenes o sonidos. Así, se diferencia de ChatGPT, que es entrenado a partir de un gran conjunto de datos etiquetados. “Para comprender lo que captura el modelo, entrenamos un decodificador estocástico que mapea las representaciones predichas de I-JEPA en el espacio de píxeles, que muestra los resultados del modelo cuando se prueba para hacer predicciones dentro del cuadro azul” , señala. Para ejemplificar cómo funciona esta nueva tecnología, Meta demostró que  su IA puede completar las imágenes de animales y un paisaje.  I-JEPA pudo reconocer “semánticamente” las partes que faltaban gracias al contexto: la pata de un pájaro o la cabeza de un perro. Por el momento, la herramienta solo está disponible para ser testeado por la  comunidad científica  y no por el público general. Este no es el primer acercamiento de Meta con la inteligencia artificial. Tiempo atrás, ya han presentado  LLaMa,  su modelo de lenguaje, y SAM, una IA que puede reconocer elementos y significados dentro de una imagen. Zuckerberg ha adelantado que planean desarrollar un asistente virtual que mejore la vida social de sus usuarios.