Meta , la empresa matriz de  Facebook , ha reafirmado su compromiso con la  inteligencia artificial  (IA) al revelar sus esfuerzos por desarrollar una infraestructura interna para potenciar la IA generativa durante un evento digital reciente. Alexis Bjorlin, vicepresidente de Infraestructura de la compañía, ha destacado la importancia de construir capacidades de hardware propias para tener un control completo en todas las etapas del proceso, lo que permitirá ampliar los límites de la investigación en IA a gran escala. A pesar de invertir considerablemente en científicos de datos y el desarrollo de IA en la última década, Meta ha enfrentado desafíos para convertir sus innovaciones de investigación en productos tangibles, especialmente en el campo de la IA generativa. Para superar estos obstáculos, la compañía ha realizado importantes cambios, como la adquisición de unidades de procesamiento gráfico (GPU) de Nvidia por miles de millones de dólares, lo que ha implicado rediseños significativos en varios de sus centros de datos. Ahora, el gigante de las redes sociales ha anunciado planes para desarrollar  el Meta Training and Inference Accelerator (MTIA), un chip interno más ambicioso que se espera esté disponible en 2025.  Este chip desempeñará un papel fundamental en el entrenamiento y ejecución de modelos de IA, y formará parte de una “familia” de chips diseñados para acelerar las cargas de trabajo de entrenamiento e inferencia de IA. Con estos esfuerzos renovados,  Meta busca aprovechar plenamente el potencial de la IA en sus aplicaciones y servicios . Se espera que estos avances internos impulsen el desarrollo de productos basados en IA y le permitan superar los desafíos que ha enfrentado hasta ahora en este ámbito, reafirmando su posición como líder en el campo de la IA. Según Bjorlin, esta solución personalizada en colaboración con el modelo, el software y el hardware del sistema, promete brindar una experiencia superior a los usuarios en una variedad de servicios. El desarrollo de chips internos para acelerar la inteligencia artificial (IA) se está volviendo cada vez más común en el sector tecnológico, y Meta se une a empresas como Google, Amazon y Microsoft que también están invirtiendo en sus propios chips para satisfacer las demandas de entrenamiento y ejecución de modelos de IA. El chip en desarrollo por Meta, conocido como MTIA, se encuentra en proceso de perfeccionamiento y se espera que mejore significativamente la eficiencia y el rendimiento en el consumo de energía al ejecutar cargas de trabajo de recomendación. En la actualidad, Meta confía en las unidades de procesamiento gráfico (GPU) de su supercomputadora de investigación, el Research SuperCluster (RSC), desarrollado en colaboración con Penguin Computing, Nvidia y Pure Storage. Esta infraestructura le ha permitido impulsar sus investigaciones en IA y mantenerse a la vanguardia de las tecnologías emergentes. Aunque el proyecto del chip MTIA aún está en desarrollo, la empresa está centrada en aumentar su eficiencia y capacidad para ejecutar cargas de trabajo de IA mejoradas y avanzadas. Además, la empresa ha anunciado el éxito de la segunda fase de desarrollo de su supercomputadora de investigación, que ahora cuenta con un impresionante total de 2.000 sistemas Nvidia DGX A100 y 16.000 GPU Nvidia A100. Esta infraestructura brinda a los investigadores una ventaja al permitirles entrenar modelos utilizando ejemplos reales de los sistemas de producción de la compañía, en contraste con la infraestructura anterior que se basaba únicamente en código abierto y conjuntos de datos públicos.