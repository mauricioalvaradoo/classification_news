Eliezer Yudkowsky es un experto en desarrollo  tecnológico , responsable del Machine Intelligence Research Institute, y también es considerado uno de los fundadores de este campo de investigación. Teniendo en cuenta su enorme trayectoria, se le ha consultado cuál es su perspectiva sobre los avances en  Inteligencia Artificial , por ejemplo  ChatGPT . En una carta, publicada en Future of Life Institute, Yudkowsky pide que “ todos los laboratorios de IA pausen inmediatamente durante al menos seis meses el entrenamiento de sistemas de  IA más potentes que GPT-4 ″. Indica que no hay un nivel de planificación y gestión, debido a que los laboratorios de IA están compitiendo en desarrollar e implementar mentes digitales cada vez más poderosas,  sobre todo porque ni siquiera sus creadores pueden entender, predecir o controlar de forma fiable. “ La investigación y el desarrollo de IA deben reenfocarse en hacer que los sistemas potentes y de última generación de hoy en día sean más precisos, seguros, interpretables, transparentes, robustos, alineados, confiables y leales ”, se puede leer. 
 
 
 
 
 Apoya su petición en que la sociedad ha hecho una pausa en otras tecnologías con efectos potencialmente catastróficos, por lo que solicita no nos apresuremos a caer sin  estar preparados para una tecnología de este nivel. GDA / Lina Hernández Serrano / El Tiempo / Colombia