La primera propuesta de  computadoras cuánticas  se hizo hace casi 30 años y desde entonces se han conseguido varios prototipos que, a medida que se hacen más potentes, necesitan de más aislamiento y de mecanismos para corregir errores. Ahora, un experimento liderado por  Google  avanza para lograr este último reto. Los sistemas cuánticos son muy sensibles al ruido -cambios de temperatura, de luz- y esto puede perturbar el cálculo y dar lugar a resultados inexactos, un problema que se ve agravado cuanto más grande es la instalación. Las computadoras clásicas están construidas con mecanismos propios para corregir errores, pero en las cuánticas sigue siendo un desafío. En esta nueva investigación, el laboratorio de inteligencia artificial cuántica de Google ha demostrado experimentalmente que  es posible reducir el número de errores aumentando el número de cúbits.  La descripción del experimento  se publica en la revista Nature . La misión de las computadoras cuánticas, como la de las convencionales y supercomputadoras, es la de hacer operaciones, cálculos que los primeros ejecutan de forma muy distinta: trabajan a nivel atómico y por lo tanto siguiendo las normas de la física cuántica (rama de la física encargada de estudiar el mundo a escalas espaciales muy pequeñas). Las computadoras cuánticas funcionan con cúbits (unidad básica de información cuántica) y no bits (como en los tradicionales). Un bit (acrónimo en inglés de binary digit -dígito binario-) es la unidad mínima de información empleada en informática o en un dispositivo digital y se representa con dos valores, 0 y 1 -todo lo que soporta el funcionamiento de una computadora clásica se escribe en estos términos-. Sin embargo, en la computación cuántica esto cambia, ya que un cubit, a diferencia de un bit, puede contener, además, ciertas combinaciones de ambos valores que no se pueden conseguir clásicamente, lo que posibilita una velocidad de procesamiento mayor. El funcionamiento de las computadoras cuánticas se basa en manipular los cúbits de forma orquestada, utilizando lo que se llama “algoritmo cuántico”. El problema, explica el director ejecutivo de Google, Sundar Pichai, es que los cúbits son tan sensibles que incluso una luz parásita puede provocar un error de cálculo. “Las consecuencias son importantes: los mejores algoritmos cuánticos que conocemos hoy día para ejecutar aplicaciones útiles requieren que los cúbits tengan índices de errores muy por debajo de los que tenemos actualmente”,  resume Pichai en una entrada en el blog de Google. La solución al problema, por tanto, pasa por corregir los errores cuánticos , y ahora,  “hemos dado otro gran paso adelante” , prosigue Pichai , “nuestro avance supone un cambio importante en el modo de funcionamiento de las computadoras cuánticas” . En las investigaciones para corregir errores de las computadoras cuánticas se habla de cúbits físicos y cúbits lógicos.  “Los primeros son los reales, es decir, el número de cúbits que están ahí, en tu experimento” , explica a EFE el investigador Carlos Sabín, del departamento de Física Teórica de la Universidad Autónoma de Madrid. El cúbit lógico es un conjunto de cúbits físicos; en los experimentos las operaciones no se realizan sobre cada cúbit físico sino sobre todo el sistema, lo que puede cambiar las propiedades y resultados, añade Sabín, que no firma el artículo de Nature. Hartmut Neven y sus colegas de Google Quantum AI han hecho así su experimento; han tratado un grupo de cúbits como un único cúbit lógico, en lugar de trabajar, uno a uno, con los cúbits físicos de un procesador. Así, desarrollaron un procesador cuántico superconductor con 72 cúbits y lo probaron de dos formas: crearon un cúbit lógico a partir de 49 cúbits físicos y otro, más pequeño, con 17 cúbits físicos. Demostraron que el más grande permitía un mejor rendimiento de los cubits lógicos.  “Por primera vez hemos conseguido aumentar la escala de un cúbit lógico y eso constituye un logro experimental” , resume Pichai. Estos resultados marcan una demostración experimental en la que la corrección cuántica de errores “empieza a mejorar” su rendimiento al aumentar el número de cúbits , “iluminando el camino” para futuros avances, aseguran los autores en Nature. Aunque este trabajo demuestra “un requisito fundamental” para ello, los investigadores reconocen que hay que seguir trabajando. Para Sabín, se trata de un trabajo que, si bien supone un avance más, es “muy, muy preliminar”. Además, la mejoría de los resultados que se consiguen en el cúbit lógico más grande es modesta; hay que seguir investigando.