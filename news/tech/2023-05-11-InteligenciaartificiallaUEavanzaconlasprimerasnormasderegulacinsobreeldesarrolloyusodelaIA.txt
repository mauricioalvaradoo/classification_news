El Comité de Mercado Interior y el de Libertades Civiles de la  Unión Europea  (UE) han aprobado este jueves un proyecto de mandato de negociación para las primeras normas de la historia para la  Inteligencia Artificial  (IA), en el que se redefinen y armonizan las pautas incluidas en el texto ya existente del reglamento europeo sobre IA, incluyendo nuevas enmiendas con normas de transparencia y gestión de riesgo para los sistemas de la IA. La aprobación de este proyecto de mandato de negociación ha tenido lugar en el marco del IA Act, que se ha celebrado este jueves, y que desde el Parlamento de la Unión Europea entienden que, una vez se apruebe, será el primer conjunto de leyes dedicadas a la regulación de la Inteligencia Artificial. Así, el proyecto de mandato ha salido adelante con 84 votos a favor, 7 en contra y 12 abstenciones. Además, los miembros del Parlamento Europeo también han aprobado algunas enmiendas que incluyen las propuestas que desean incluir en la posible Ley sobre IA, que fue planteada por la Comisión en el año 2021. Antes de que estas negociaciones comiencen a debatirse en el Consejo Europeo para lanzar la reforma final de la ley, el proyecto de mandato de negociación ha de ser refrendado por todo el Parlamento Europeo. En este sentido, el Parlamento ha señalado que se espera que dicha votación tenga lugar entre los días 12 y 15 de junio. Con las enmiendas se busca garantizar que los sistemas de IA estén supervisados por personas, que sean transparentes, que eviten la discriminación y que, incluso, sean respetuosos con el medio ambiente. Así, en caso de que este reglamento se lanzase como ley en un futuro, con los añadidos de las enmiendas aprobadas por los miembros del Parlamento Europeo, estos serían algunos de los puntos más relevantes de la Ley sobre Inteligencia Artificial. En general, según explica el Parlamento Europeo en un comunicado en su web, las normas del texto establecen obligaciones tanto para proveedores como para usuarios, en función del nivel de riesgo que pueda generar la IA en determinadas situaciones. En base a ello, si se determina que el sistema de IA tiene un nivel “inaceptable” de riesgo para la seguridad de las personas, este queda “estrictamente prohibido”. Es decir, según se especifica con estos parámetros, quedarían prohibidos sistemas de IA que utilicen técnicas subliminales, que lleven a cabo manipulación intencionada o que exploten vulnerabilidades de las personas. También quedarían prohibidos aquellos sistemas que se utilicen para el ‘scoring’ social, esto es, una clasificación de las personas en función de su comportamiento social o su estatus socioeconómico. Siguiendo esta línea, las enmiendas de los miembros del Parlamento también incluyen algunas prohibiciones respecto a la tecnología del reconocimiento facial. En concreto, se prohíben sistemas de identificación biométrica remota en tiempo real en espacios de acceso público. Con ello se pretende evitar que, por ejemplo, se puedan utilizar cámaras de seguridad para recoger datos de reconocimiento facial. Asimismo, también se prohíbe el uso de esta tecnología para categorizar a las personas con características sensibles como el sexo, la raza, la religión o la orientación política. Lo mismo ocurre con el uso de los sistemas de reconocimiento de emociones en las fuerzas del orden, la gestión de fronteras, el lugar de trabajo o las instituciones educativas. Continuando con las fuerzas del orden, se prohíbe el uso de sistemas de IA para desarrollar sistemas policiales predictivos, que basan sus conocimientos de perfiles, localización o comportamientos delictivos anteriores de un usuario para predecir si volverá a cometer un acto ilegal. Estas enmiendas también recogen la protección de los daños a la salud, la seguridad, los derechos fundamentales o el medio ambiente como áreas de alto riesgo a la hora de utilizar sistemas de IA. Por ejemplo, se hace referencia a los daños de derechos fundamentales que hacen los sistemas de IA para influir en votantes en las campañas políticas. Los miembros del Parlamento también se han dirigido en sus enmiendas a los proveedores de modelos de cimentación para las IA, es decir, aquellas empresas que proporcionan modelos de desarrollo nuevo. En concreto, disponen que dichas empresas deberán garantizar la protección de los derechos de los usuarios, tanto la seguridad, como la democracia o la salud. Para ello, el Parlamento ha explicado que deberán “evaluar y mitigar los riesgos” de su sistema de IA, así como cumplir los requisitos de información y medio ambiente de la Unión Europea e inscribirse en su base de datos. Asimismo, los miembros del Parlamento Europeo han hecho hincapié en la IA de ChatGPT, desarrollada por OpenAI, a la que exigen cumplir “requisitos adicionales de transparencia”. Así, quienes la utilicen deberán especificar qué contenido ha sido desarrollado por la IA y cual no. También deberán asegurar que el modelo no generará contenido ilegal, incluido el uso de datos protegidos por derechos de autor “utilizados para el entrenamiento”. No obstante, de cara a seguir impulsando la innovación en esta tecnología, los miembros del Parlamento han nombrado algunas excepciones a estas prohibiciones, siempre de cara a la investigación de componentes de la IA “proporcionados bajo licencias de código abierto”. En este sentido, dentro de las enmiendas se ha propuesto la creación de “entornos controlados” por las autoridades públicas para probar las innovaciones de la IA antes de que llegue a las manos de los usuarios. Además de todo ello, los miembros del Parlamento Europeo también han aprobado una enmienda para introducir en el texto una definición “uniforme y neutra” de la Inteligencia Artificial, que pueda aplicarse tanto a los sistemas de IA de hoy en día como a los de mañana.