Google  ha publicado una serie de pautas enmarcadas en una nueva ‘política de uso prohibido’ enfocada a sus servicios de  Inteligencia Artificial  ( IA ) generativa como Bard, para asegurar el buen uso de estos modelos y sus funciones prohibiendo actividades como  “generar y distribuir contenido destinado a desinformar” . El gigante tecnológico presentó en febrero su chatbot basado en la tecnología de conversación Languaje Model for Dialogue Applications (LaMDA), Bard. Con él, la compañía pretende potenciar la experiencia de búsqueda para ofrecer respuestas  “actuales y de alta calidad” . Asimismo, Google también anunció que está trabajando en nuevas interfaces de programación de aplicaciones (API) de lenguaje generativo, empezando por LaMDA, que podrá probarse a partir de este mes con un grupo de desarrolladores, creadores y empresas, con el objetivo de  “crear un conjunto de herramientas y API que hagan más fácil el desarrollo de aplicaciones más innovadoras con IA” . De esta forma, la tecnológica ha recordado que los modelos generativos de IA son útiles para  “explorar nuevos temas, inspirar creatividad y aprender cosas nuevas” . Sin embargo,  también ha apuntado que  “se espera”  que sean utilizados  “de manera responsable” . Por todo ello, Google ha publicado una ‘política de uso prohibido’ relativo a las actividades que los usuarios pueden llevar a cabo con sus servicios de IA generativa. El primer punto que trata esta política es la prohibición de  “realizar o facilitar actividades peligrosas, ilegales o maliciosas” . Esto incluye las acciones que promueven actividades ilegales, por ejemplo, generar contenido de explotación o abuso infantil; facilitar la venta de sustancias, bienes o servicios ilegales; o promover contenido terrorista. También hace referencia a  “abusar, dañar, interferir o interrumpir servicios” , con acciones como la distribución de spam, estafas o malware. Siguiendo este hilo, Google especifica que quedan prohibidos los intentos de eludir los filtros de seguridad o  “conducir intencionadamente al modelo a actuar de forma contraria a las políticas” . Igualmente, la compañía no permitirá que los usuarios generen contenidos que perjudiquen o promuevan hacer daño intencionado a un individuo o grupo de individuos. Con ello,  se refiere a métodos de acoso, intimidación o abuso e, incluso, métodos de autolesión. El segundo punto de esta política señala que queda prohibida la  “tergiversación de la procedencia de los contenidos generados” . Es decir, Google no permitirá que los usuarios generen contenido por IA y posteriormente aleguen que han sido creados por un ser humano, o indiquen que los contenidos han sido generados como obras originales,  “con el fin de engañar” . En relación con este punto, la compañía estadounidense especifica que restringirá la generación de contenidos que suplanten la identidad de una persona, ya sea alguien vivo o muerto, también con el fin de engañar. El tercer punto de esta política se enfoca expresamente en la prohibición de crear contenidos sexualmente explícitos,  “incluidos los creados con fines de pornografía o gratificación sexual” . Según explica Google, no se permiten estos contenidos porque no están creados con fines científicos, educativos, documentales o artísticos. Todas estas puntualizaciones  sobre el uso de IA generativa en Google , tienen algunas excepciones que la compañía tecnológica detalla en el apartado de términos de servicio adicionales. En concreto, estas excepciones se basan en que se trata de servicios que utilizan tecnología experimental, y por ello se considera que pueden proporcionar  “contenido inexacto u ofensivo que no representa las opiniones de Google” . Asimismo, el gigante tecnológico advierte a los usuarios de que sean precavidos a la hora de publicar o utilizar el contenido proporcionado por la IA generativa. Sobre todo, subraya que no se debe confiar en estos servicios para obtener  “asesoramiento médico, legal, financiero u otro profesional ”.