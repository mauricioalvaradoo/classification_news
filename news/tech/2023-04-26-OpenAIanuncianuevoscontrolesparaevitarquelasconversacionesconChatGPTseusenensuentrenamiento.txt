OpenAI  ha introducido nuevos controles en la gestión de su ‘chatbot’  ChatGPT  para que los usuarios puedan optar por no utilizar las conversaciones que mantienen con él para entrenar los modelos de lenguaje. La compañía de inteligencia artificial ha anunciado  nuevos ajustes para proteger los datos de los usuarios  que acceden a ChatGPT, así como una nueva suscripción para empresas con controles adicionales para su gestión. Los usuarios de ChatGPT encontrarán desde este martes un nuevo ajuste que permite  desactivar el historial de conversaciones , de tal forma que las conversaciones que se inicien después de marcarlo ya no se utilizarán para entrenar los modelos de OpenIA. Sin embargo, como matiza la compañía, se guardarán durante 30 días en caso de que sea necesario revisar dichas conversaciones en caso de abuso. Pasado ese plazo, se eliminarán, como explica en su  blog oficial . La  opción de Exportar , por su parte, permitirá obtener  un archivo con las conversaciones mantenidas  con el ‘chatbot’ para comprender mejor la información que ChatGPT almacena. Y para los profesionales que necesitan controles adicionales para garantizar la seguridad de los datos de sus clientes, OpenAI ha anunciado una nueva  suscripción, ChatGPT Business,  que garantizará que por defecto no se usarán dichos datos para entrenar los modelos de lenguaje.