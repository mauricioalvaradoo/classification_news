El ‘chatbot’ de  Google , Bard, va a mejorar con modelos de lenguaje más potentes que lo dotarán de nuevas capacidades, como la de programar, pero su avance tiene que hacerse de la forma correcta, atendiendo a cuestiones como la privacidad y la seguridad, según ha explicado el director ejecutivo de Google, Sundar Pichai, que afirma que se trata de un área  “demasiado importante para no regularlo bien”. Google presentó  Bard a principios de febrero, un ‘chatbot’  basado en la tecnología de conversación  Languaje Model for Dialogue Applications (LaMDA) , con el que espera potenciar la experiencia de búsqueda para ofrecer  “respuestas actuales y de alta calidad”. Se trata de su respuesta a ChatGPT y el modelo de lenguaje GPT que lo potencia, desarrollados por OpenAI, un  avance en la aplicación de la inteligencia artificial  (IA) que ha puesto en alerta al gigante tecnológico y lo ha desbancado de su posición de liderazgo en este área de investigación y desarrollo. Bard tiene en su base una versión ligera y eficiente de LaMDA , como ha recordado el directivo en el pódcast ‘Hard Fork’, de The New York Times. En comparación con otros chatbots existentes, es como si hubieran cogido “Un Civic mejorado” y lo hubieran puesto “en una carrera con autos más potentes”. El directivo reconoce que son prudentes con su IA, lo que ha generado entre los usuarios que ya han podido probarlo la impresión de que está por detrás del ‘chatbot’ estrella del momento, ChatGPT de OpenAI. Sin embargo, se trata de una prueba. “Queríamos ver qué tipo de consultas obtendríamos”, indica.  “Claramente tenemos modelos más capaces. Muy pronto,  tal vez a medida que esto se active, actualizaremos Bard a algunos de nuestros modelos PaLM más capace s, por lo que traerá más capacidades, ya sea en razonamiento, codificación. Puede responder mejor a las preguntas de matemáticas. Así que verán progreso en el transcurso de la próxima semana” , anticipa. “Era importante no poner un modelo más capaz antes de que podamos asegurarnos de que podemos manejarlo bien” , añade el directivo, que reafirma su postura de ser cautelosos:  “no quiero que sea solo quién está allí primero, pero hacerlo bien es muy importante para nosotros”. A mediados de marzo, la compañía anunció la  implementación de IA generativas  —con capacidad para generar contenidos originales sin intervención humana a partir de una descripción en texto— en sus  servicios de ofimática, empezando en Gmail y Docs. Por el momento, esta implementación está en pruebas con un grupo limitado de usuarios, que tienen acceso a funciones básicas potenciadas por esta IA, como la composición de un ‘email’ a partir de unas pocas indicaciones. Pero la compañía es más ambiciosa con las posibilidades que ofrece. “Conseguir que todos tengan su propio modelo personalizado, [...]esto es lo que imaginamos cuando estábamos construyendo el Asistente de Google. Pero tenemos la tecnología para hacer esas cosas ahora”, afirma el directivo. Actualmente, una de las cosas que han detectado en Google en las pruebas con Bard es que los desarrolladores preguntan por muestras de código. Precisamente, Pichai ha señalado que  Bard tendrá “pronto” capacidad para programar, similar a lo que ya ofrecen Codex y Copilot en los servicios de Microsoft. OpenAI lanzó  ChatGPT  en noviembre del año pasado y a principios de febrero,  Microsoft anunció su integración en las nuevas versiones del buscador Bing y del navegador Edge , con una gran acogida por parte de los usuarios, quienes pudieron apuntarse a una lista de espera para empezar a probarlo, aunque ya está disponible para todos. Solo un día después Google anunció Bard, pero bajo la impresión de que llegaba tarde a un sector que había dominado hasta hacía poco, con los avances de sus propios equipos, como los modelos LaMDA y PaLM, y la división DeepMind, responsable, por ejemplo, de AlphaGo, la  IA que logró derrotar a un profesional del Go, y de AlphaFold , capaz de predecir la estructura de una proteína basada únicamente en su secuencia genética. Los avances más destacados en IA incluyen la arquitectura de red neuronal Transformer, creada por Google Research en 2017, que produce un modelo que puede ser entrenado para leer palabras, prestar atención a la relación entre ellas y predecir cuáles vendrán a continuación. También el  Modelo Unificado Multitarea (MUM), también de Google  y presentado en 2021, capaz de comprender la noción del consenso. Esto es, cuando múltiples fuentes fiables están de acuerdo con el tipo de información que se ofrece, lo que le permite comparar textos destacados de fragmentos y el tipo de palabras que se utiliza para describir el mismo concepto. “Tomamos modelos de  Transformer  para ayudar a mejorar la comprensión del lenguaje y buscar profundamente. Y ha sido uno de nuestros eventos de mayor calidad durante muchos, muchos años”,  ha explicado el directivo de Google, lo que le lleva a apuntar que llevan mucho tiempo incorporando la IA en las búsquedas. “Hemos sido muy prudentes en cómo nos estamos moviendo en este momento. Algunos de estos productos podríamos haberlos puesto el mercado antes. Nos estamos tomando nuestro tiempo para hacer eso, y seguiremos siendo muy, muy responsables” , ha reiterado. “El trabajo que hacemos en torno a la privacidad, la seguridad, la IA responsable, creo, en todo caso, es más importante. Y, entonces, nuestro compromiso allí va a ser inquebrantable, para hacer todo esto bien” , asevera el directivo. Precisamente por ello comparte la preocupación que esta semana ha motivado una carta abierta, firmada por, entre otros, el director ejecutivo de Tesla, SpaceX y Twitter, Elon Musk, quien ayudó a fundar OpenAI, en la que se solicita  detener las grandes investigaciones con IA  para dotar a este sector de una normativa que garantice su desarrollo seguro para la sociedad y la humanidad. Pichai sostiene que  “la IA es un área demasiado importante para no regularla. También  es un área demasiado importante para no regularla bien ”.