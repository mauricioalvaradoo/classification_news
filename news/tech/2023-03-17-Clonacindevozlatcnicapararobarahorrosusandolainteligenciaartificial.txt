La  inteligencia artificial (IA)  sigue mostrando avances, pero también nos deja varias dudas ya que también la están usando los  ciberdelincuentes  con el uso de clonadores de voz de familiares y engañar a sus víctimas. Y es que el método no es nuevo. Los delincuentes suelen llamar por teléfono a sus víctimas y pedir ayuda económica. Se trata del segundo tipo de robo en Estados Unidos, que ha generado pérdidas de 11 millones de dólares el año pasado. Lo diferente es que ahora utilizan programas de inteligencia artificial para generar las voces de un familiar, que supuestamente está en apuros y necesita dinero de manera urgente. Es así como pueden hasta robar los ahorros de sus víctimas. Se trata de un trabajo un poco más complejo. Para replicar la voz de una persona se necesita de una muestra de audio, aunque sea breve y de pocas oraciones. Por ejemplo, según informe de  El Español Omicrono , se puede extraer el tipo de voz de videos de TikTok, Instagram o Podcast. Ahora los estafadores trabajan con la IA y puede recrear perfectamente el tono, el timbre y los sonidos individuales de la voz de una persona determinada. Un hijo, un amigo o un amante, son el tipo de personas más clonadas. Pero también hay un problema con las empresas de Inteligencia Artificial. Hasta el momento no existen precedentes legales para responsabilizarlas; es decir, hay un camino libre para el mal uso de esta tecnología que está en constante evolución.