Meta  ha presentado LIMA, un modelo de lenguaje grande con el que demuestran que se pueden obtener respuestas de alta calidad a partir de un conjunto pequeño de indicaciones con un modelo previamente entrenado. LIMA (Less Is More for Alignment) se basa en LLaMa, un modelo con 65.000 millones de parámetros que la compañía tecnológica facilitó con fines investigadores en el primero trimestre del año. Meta explica que los grandes modelos de lenguaje habitualmente se entrenan en dos fases: una formación previa no supervisada de texto sin procesar, para que aprenda representaciones generales, y otra a gran escala de aprendizaje mediante ajuste y refuerzo, con la que se busca que la IA se alinee mejor con las tareas finales y las preferencias del usuario. Con LIMA , Meta pretende demostrar que es posible obtener resultados de calidad a partir de unas pocas indicaciones con un modelo que ha sido ampliamente entrenado con anterioridad.  Y para ello, ha utilizado mil ejemplos de instrucciones reales cuidadosamente curadas, 750 procedentes de foros como Stack Exchange y wikiHow y otras 250 redactados por los propios investigadores. Para analizar su rendimiento,  lo han comparado con GPT-4 de OpenAI, Claude de Anthropic y Bard de Google con un test controlado de 300 indicaciones . Los resultados que obtuvieron muestran que LIMA produce respuestas “iguales o preferibles” en el 43%, el 46% y 58% de los casos, respectivamente. 
 Como recogen en el estudio publicado en  arxiv.org , en una escala absoluta, las respuestas de LIMA  “revelan que el 88% cumple con los requisitos inmediatos, y el 50% se considera excelente” , apuntan los investigadores.