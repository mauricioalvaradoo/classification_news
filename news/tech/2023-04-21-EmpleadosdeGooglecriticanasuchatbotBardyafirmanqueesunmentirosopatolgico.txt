Google se encuentra en una carrera contra el tiempo para lanzar su nuevo modelo de  inteligencia artificial , Bard, que competirá contra ChatGPT de OpenAI. Sin embargo, según un  informe  de Bloomberg que entrevistó a 18 empleados de  Google , el equipo de ética de IA de la compañía está siendo desplazado para acelerar el lanzamiento de Bard al mercado. Los trabajadores de Google realizaron pruebas a Bard y proporcionaron comentarios, pero la retroalimentación fue completamente ignorada internamente para que Bard se lanzara lo antes posible. Según el informe, varios empleados internos de Google describieron a Bard como “digno de vergüenza” y “un mentiroso patológico”, debido a sus respuestas incorrectas y peligrosas a preguntas simples. A pesar de que Bard está diseñado para responder preguntas complejas,  parece estar muy por detrás de ChatGPT en términos de capacidad y fiabilidad . Incluso los ingenieros de Google han advertido que Bard es peor que inútil y han pedido a la compañía que no lo lance todavía. Mientras tanto, ChatGPT sigue siendo una preocupación para Google, ya que su capacidad para responder a preguntas complejas  lo convierte en una alternativa viable a las búsquedas en el motor de búsqueda de Google . Aunque ChatGPT también tiene sus propias fallas, parece estar lo suficientemente avanzado como para poner nerviosos a los ejecutivos de Google. Meredith Whittaker, ex gerente de Google y presidente de Signal Foundation, advirtió que si Google descuida sus principios éticos en la IA, complicará la vida de Bard en el futuro. A medida que la IA se vuelve más avanzada y se integra en nuestras vidas cotidianas, es importante que las empresas sigan estrictos estándares éticos para garantizar la seguridad y la fiabilidad de estas tecnologías. En conclusión, Google se encuentra en una posición difícil mientras intenta apresurar el lanzamiento de Bard para competir con ChatGPT. Aunque la tecnología de IA promete revolucionar el mundo, es importante que las empresas sigan estrictos estándares éticos para garantizar que estas tecnologías no pongan en peligro a los usuarios.