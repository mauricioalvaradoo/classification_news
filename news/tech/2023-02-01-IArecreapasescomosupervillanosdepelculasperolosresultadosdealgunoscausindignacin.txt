Midjourney es una de las IA de moda en la actualidad debido a que genera imágenes impresionantes y que cualquier usuario puede usar. Cuando el usuario de TikTok @ailoubfreitas le pidió recrear los países como si fueran supervillanos, el mundo se maravilló con lo que esta  inteligencia artificial  dio como resultado. Sin embargo, algunas personas han notado los sesgos que puede tener esta tecnología. En el caso de Perú, por ejemplo, la IA generó una especie de semidios con atributos precolombinos. La mayoría de su vestimenta y colores son una mezcla de varias culturas de toda América, con colores más ligados a las zonas centroamericanas y el actual México.  Este tipo de recreación con características erróneas se deben a que la inteligencia artificial utiliza internet, en inglés, para obtener su información , por lo que mezcla las culturas antiguas de Latinoamérica como si fuera una sola. Puedes ver algunas de las imágenes en la siguiente  galería . Sin embargo, el gran problema que causó indignación no se dio debido a un error de la IA. En cambio, fue por  los sesgos obtenidos desde internet para generar algunas imágenes . Por ejemplo, el caso de Venezuela, donde  el “supervillano” se parece a Nicolás Maduro y tiene una vestimenta parecida a la del libertador Simón Bolívar . Algunos partidarios del actual presidente venezolano criticaron la imagen pues antagoniza a su líder. Asimismo, da una mala imagen de Bolívar, el cual es una de las figuras históricas del continente. El caso de Colombia fue el llamativo, pues  el “supervillano” fue representado como un hombre con partes robóticas, pero que porta varias armas . Algunos medios incluso calificaron la recreación como si fuese un “sicario”. Esto se debe al prejuicio en contra del país, el cual pulula por todo internet.  Otros usuarios relacionaron la imagen con la idea del narcotráfico , pues es uno de los problemas más grandes de la región latinoamericana.     @bymartinlopez   #greenscreen   #ia   #midjourney   #venezuela   #colombia  @Freitas AI Art  #paises   ♬ Suspense, horror, piano and music box - takaya       Los estereotipos en las inteligencias artificiales no es algo nuevo . Una IA no genera información en base a lo que ve, siente o experimenta, como los humanos. Por el contrario, en casos como Midjourney, recibe información por parte de los creadores y los usuarios, y luego busca datos en internet. Es decir,  no discierne entre lo que está bien o mal , lo que es cierto o falso, o entre lo ético y no ético. Por ello, si al buscar ‘Perú' solo encuentra fotos de Machu Picchu, recreará imágenes en base a ello. Un ejemplo claro son  los temores de algunos expertos con respecto a  una IA creada por la Universidad de Chicago . Esta predice crímenes con una semana de anticipación y con un 90% de precisión. Fue creada en base a datos históricos de delincuencia de Chicago, Illinois, desde 2014 hasta finales de 2016. Es decir,  fue entrenada por los reportes de la policía . Si bien todo parece perfecto hasta ahí, en realidad el problema se genera cuando no se disciernen los reportes. Esto se debe a que, suponiendo que los policías han relatado la verdad,  no solo incluyen los reportes reales, juicios y demás archivos de los casos, sino también las denuncias que realizan los ciudadanos, las cuales muchas veces están basadas en prejuicios o mentiras . La IA, sin embargo, toma la información como un “hecho”, por lo que podría terminar perjudicando a las minorías raciales. Solo con un algoritmo utilizado por el Departamento de Policía de Chicago que creaba una lista de personas consideradas en mayor riesgo de estar involucradas en un tiroteo,  el 56% de los hombres afroamericanos de entre 20 y 29 años figuraban en ella . El caso de Midjourney no es tan extremo ni tiene consecuencias graves, pero  sí afecta a la representación de las personas . Con los países, añade más prejuicios en contra de millones simplemente porque en internet esta plasmado de esa manera y la inteligencia artificial lo toma como algo real.