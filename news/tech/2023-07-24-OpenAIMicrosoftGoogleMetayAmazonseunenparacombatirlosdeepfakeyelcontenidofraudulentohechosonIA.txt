OpenAI ,  Microsoft ,  Google ,  Meta  y  Amazon  se han reunido con el presidente de los Estados Unidos, Joe Biden, para presentar una solución definitiva para identificar los deepfakes y contenido generado por  inteligencia artificial . La propuesta es el uso de marcas de agua. A partir de ahora, todo el contenido creado por ChatGPT, MidJourney, Stable Diffusion, Google Bard y el Chat de Bing llevará una marca de agua que permitirá identificar rápidamente su origen y qué IA lo generó. Además de este método, las compañías han acordado otras medidas para reducir los riesgos asociados con la IA. Se comprometen a someterse a controles internos y externos realizados por expertos en seguridad independientes antes de lanzar una nueva IA o una versión actualizada de una inteligencia artificial generativa. También se comprometen a compartir información sobre el funcionamiento de sus IAs con gobiernos, expertos y académicos para identificar posibles riesgos de seguridad. Estas empresas líderes también implementarán normativas especiales en cuanto a temas delicados, como el desarrollo de armas biológicas, químicas o radiológicas utilizando IA, herramientas de ciberdelincuentes, control físico de máquinas y dispositivos, discriminación racial y de género, y la posibilidad de autorreplicación de una IA.