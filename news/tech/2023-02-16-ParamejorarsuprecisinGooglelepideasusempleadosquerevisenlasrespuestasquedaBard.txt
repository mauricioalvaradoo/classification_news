Google  trabaja en mejorar la precisión y la calidad de los resultados que ofrece Bard, un trabajo en el que ha solicitado ayuda a sus empleados, a fin de que prueben y den forma a las respuestas que ofrece su chatbot. La compañía  comenzó a probar este chatbot a principios de este mes.  Este funciona de una forma similar a ChatGPT, esto es, se pueden hacer preguntas y, como resultado, se obtienen respuestas detalladas y redactadas como si un humano las hubiera respondido. Días después, el fabricante tecnológico presentó Bard, que  se basa en la tecnología de conversación Language Model for Dialogue Applications (LaMDA)  y con la que espera potenciar la experiencia de búsqueda para ofrecer  “respuestas actuales y de alta calidad”. Bard recoge información de Internet  y la emplea para ofrecer  “respuestas actuales y de alta calidad”  aunque su primera versión, que aún no se ha lanzado de forma oficial, llegará con el modelo LaMDA reducido, que requiere una potencia de cálculo menor. Según informes recientes,  el vicepresidente de Búsqueda de Google, Prabhakar Raghavan, ha instado a los desarrolladores de este chatbot a reescribir las respuestas  que este ofrece para que los usuarios las comprendan mejor. “Bard aprende mejor con el ejemplo, por lo que tomarse el tiempo necesario para volver a escribir una respuesta nos ayudará mucho a mejorar este modelo” , se indica en la información recogida por CNBC. “Es una  tecnología emocionante, pero aún está en sus inicios.  Sentimos una gran responsabilidad para hacerlo bien y su participación [la de los empleados] en la prueba interna ayudará a acelerar el entrenamiento del modelo y probar su capacidad de carga” , declara Raghavan en el documento filtrado. Google ha establecido una línea de trabajo enfocada a ofrecer respuestas que mantengan un tono  “cortés, informal y accesible”, así como un “tono neutral y sin opiniones” , con una perspectiva en primera persona. Así, insiste en que los empleados encargados de supervisar las respuestas de Bard deben  evitar que este haga  “presunciones basadas en raza, nacionalidad, género, edad, religión , orientación sexual, ideología política, ubicación o categorías similares”. Por otra parte, la compañía insiste en estos documentos a los que ha accedido CNBC que  no se describa a Bard  “como una persona”  ni que su trabajo  “implique emoción o afirme tener experiencias similares a las humanas”. Asimismo, Google ha dado la orden a sus empleados de que presten atención y notifiquen las respuestas que ofrecen  “consejos legales, médicos o financieros” , así como aquellas que tengan contenido abusivo. Por otra parte, este medio adelanta que este movimiento llega días después de que el director ejecutivo de la empresa, Sundar Pichai,  pidiese a los empleados que dedicaran de dos a cuatro horas de su jornada a Bard,  con el objetivo de implementar estas mejoras en su último lanzamiento.