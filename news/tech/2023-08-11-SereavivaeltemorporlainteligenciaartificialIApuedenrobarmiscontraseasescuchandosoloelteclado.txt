La  inteligencia artificial  (IA) es un misterio. Cada vez hay nuevas sorpresas de lo que se puede hacer con esta tecnología, algunas más peligrosas que otras como esta nueva propuesta en la que se podría robar contraseñas escuchando el sonido del teclado. Se trata de un modelo de deep learning, investigado por un grupo de la Universidad de Cornell, en Estados Unidos, que podría robar datos a través de pulsaciones registradas en un teclado mediante un micrófono. Según la página  El Español Omicrono , lo que genera más temor es que es tremendamente preciso, con una tasa de acierto del 95%. Sin embargo, su aplicación en un escenario real podría tomar más tiempo. Por otro lado, junto a los resultados del estudio liderado por Joshua Harrinson, Maryam Mehrnezhad y Ehsan Toreini también se ha propuesto sistemas y métodos para evitar ser víctima de estos ataques. ¿Cómo lo han hecho? Los investigadores entrenaron un algoritmo de clasificación de audio, con la finalidad de registrar las pulsaciones de los teclados, y también han hecho pruebas con el iPhone13 por lo que crece el temor de ser usado por la ciberdelincuencia. Pero, adelantándose a esta situación de vulnerabilidad, se sugiere alterar los estilos de escritura o usar contraseñas completamente aleatorias. También se puede usar sonidos que confundan al modelo, como ruido blanco, filtros de audios basados en software o incluso la reproducción de sonidos.