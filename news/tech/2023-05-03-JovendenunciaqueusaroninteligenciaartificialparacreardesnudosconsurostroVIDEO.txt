Cada vez es más común escuchar que la  Inteligencia Artificial  está presente en varios aspectos de la vida del ser humano. Desde bots capaces de ayudar en las tareas del día a día, hasta distintas polémicas por el mal uso que personas le dan a estas herramientas alrededor del mundo. Una de las más preocupantes, pero tal vez con menos protagonismo, trata sobre la violencia de género producida por los ‘deepfakes’, lo cual, según la empresa antifraude SEON,   “es un video, una imagen o un audio generado que imita la apariencia y el sonido de una persona” . Hace algunos años ya se hablaba del tema, especialmente porque esta tecnología se ha prestado para hacer estafas por llamadas telefónicas.   No obstante, esta también ha sido utilizada de manera negativa por personas que crean desnudos de mujeres sin su consentimiento. Entre las últimas denuncias estuvo la de una joven en TikTok, quien explica que sujetos tomaron fotos de sus redes sociales y pagaron para que,  con inteligencia artificial, pudiesen  “crear”  desnudos de ella  y difundirlos en internet. “No puedo describir lo que me ha pasado en las últimas 48 horas (...) un usuario de Twitter me envió fotografías en las que originalmente estaba vestida, totalmente vestida y las colocaron a través de una inteligencia artificial para editarme desnuda” , explicó la usuaria por medio del video. Tras esto, la mujer explicó que sus redes sociales se llenaron de mensajes directos de personas que le enviaban sus fotos editadas. “Yo no vendo contenido. Nada de eso es real. Todo esto es muy desagradable. Todos los comentarios eran realmente horribles”, declaró.     @rache.lzh5   u deserve nothing   ♬ original sound - rach       Frente a esto varios usuarios han demostrado su constante preocupación, especialmente por  cómo la inteligencia artificial se está utilizando con el fin de violentar contra una persona.   Frases como  “es realmente preocupante” ,  “tengo mucho miedo de que pueda pasarme”  o  “lamento mucho que estas situaciones se presenten”  llenaron los videos de denuncia publicados por la joven. Cabe resaltar que este no es el primer caso que sucede. Varias mujeres han sido víctimas de estas prácticas. Entre ellas la streamer QTCinderella, quien hace unos meses informó por medio de sus redes que habían colocado su rostro en un video pornográfico. Aunque trató de demandar, lamentablemente no pudo llegar a un acuerdo o a un proceso formal debido a que son muy pocos los lugares que tienen leyes puntuales sobre el deepfake y contenidos asociados. GDA / El Tiempo / Colombia