Musk  formó parte de un pequeño grupo que fundó el laboratorio de  IA  en 2015 como una organización sin fines de lucro, con la intención de que la empresa comparta la investigación para el beneficio más amplio de la sociedad. Pero a principios de 2018, señaló Semafor, a Musk le preocupaba que la empresa se estuviera quedando atrás de Google. Según los informes, se ofreció a tomar el control directo de OpenAI y ejecutarlo él mismo, pero fue rechazado por otros fundadores de OpenAI, incluidos Sam Altman, ahora director ejecutivo de la empresa, y Greg Brockman, ahora su presidente. Crucialmente, cuando Musk se alejó de la compañía (renunció a su directorio en 2018 citando un conflicto de intereses con su trabajo en Tesla), Semafor dice que también incumplió su promesa de proporcionar mil millones de dólares en fondos, contribuyendo solo con 100 millones de dólares antes de retirarse. Esto dejó a OpenAI con un problema, ya que su trabajo en el desarrollo de modelos de IA a gran escala como el generador de imágenes DALL-E y la serie GPT de generación de texto estaba acumulando enormes facturas. Entonces, para 2019, OpenAI anunció que estaba creando una nueva entidad con fines de lucro para financiar su investigación y rápidamente se enredó estrechamente con Microsoft, que proporcionó miles de millones en fondos y recursos al tiempo que aseguró licencias exclusivas para usar la tecnología de OpenAI en sus productos. Semafor no afirma abiertamente que la pérdida de fondos de Musk fue lo que empujó a OpenAI a hacer tratos con Microsoft, pero es una interpretación plausible. Esto es lo que hace que el informe sea tan significativo, ya que muchos en la comunidad de IA ven el giro de OpenAI hacia los intereses corporativos como un gran momento para la IA y el mundo, no solo como una traición a los principios fundacionales de OpenAI, sino como un estímulo para que la empresa lance nuevos productos de IA lo más rápido posible, una actitud que muchos creen que podría tener consecuencias peligrosas. El cierre del acceso a los modelos de OpenAI El giro de OpenAI hacia Microsoft sin duda ha cambiado la forma en que la empresa comparte su investigación. Cuando OpenAI anunció su último modelo de lenguaje de IA, GPT-4, a principios de este mes, muchos expertos se sintieron consternados porque no compartió detalles sobre cómo se creó o sus datos de entrenamiento. En una entrevista con The Verge , Ilya Sutskever, científico jefe de OpenAI, explicó que esto era para mantener la ventaja competitiva de la empresa sobre sus rivales (y, como consideración futura, para detener el mal uso de su tecnología). Pero muchos expertos en inteligencia artificial dicen que cerrar el acceso a los modelos de OpenAI dificulta que la comunidad comprenda las amenazas potenciales que plantean estos sistemas y concentra el poder en manos corporativas. Desde que OpenAI se alió con Microsoft, las dos compañías han estado lanzando servicios y productos de IA a un ritmo vertiginoso, con Microsoft integrando la tecnología de OpenAI en Windows y su paquete de Office. Y justo esta semana, OpenAI anunció que ampliaría enormemente las capacidades de su chatbot ChatGPT al permitir que el sistema interactúe con otros sitios y servicios a través de complementos. OpenAI dijo que era como darle al bot  “ojos y oídos” , mientras que algunos expertos expresaron su preocupación de que la medida representa una amenaza para la seguridad. Musk ha expresado su consternación por este cambio en la trayectoria de OpenAI en numerosas ocasiones. En febrero, tuiteó que OpenAI  “se ha convertido en una empresa de código cerrado y de máximo beneficio controlada efectivamente por Microsoft” , y agregó que esto  “no era lo que pretendía en absoluto” . GDA / El Universal / Juan Carlos Peña / México