Los chatbots con  inteligencia artificial  (IA) no pueden llegar a ser más inteligentes que las personas, porque estas herramientas necesitan del “juicio humano” en el sentido de que son las personas las que les indican “qué hacer”, según la opinión de un experto designado por  Microsoft . El vicepresidente corporativo y director de marketing del consumidor de Microsoft, Yusuf Mehdi, sale así al paso en una entrevista con EFE de las alarmas que ha encendido entre numerosos expertos el rápido avance de la inteligencia artificial y el peligro de que quede fuera de control. “ El núcleo de la IA es predecir texto. Es predecir qué es lo que viene después. Pero necesita del juicio humano. Los humanos son los que conectan con la IA y le dicen a la IA qué hacer ”, insiste. Mehdi explica estos miedos en parte por la novedad de esta herramienta, que se popularizó con el lanzamiento de ChatGPT de OpenIA hace seis meses, así como con los anuncios de chatbots de IA en los buscadores de Edge y Google -Bing y Bard, respectivamente-, hace tres meses. “Tenemos que pasar por este ciclo de comprensión de la tecnología (...) Y a medida que aprendamos más, creo que esos (miedos) pasarán ”, recalca. No obstante, otros expertos, como el británico Geoffrey Hinton -quien fue bautizado como el “padrino” de la IA y trabajó para Google-, señaló hace poco sus preocupaciones sobre los peligros que plantean estas nuevas tecnologías en una entrevista con The New York Times. “ La idea de que estas cosas en realidad podrían volverse más inteligentes que las personas, algunas personas lo creían ”, explica. “ Pero la mayoría de la gente pensaba que estaba muy lejos. Yo pensaba que estaba muy lejos. Pensaba que faltaban entre 30 y 50 años o incluso más. Obviamente, ya no pienso eso ”, añadía Hinton en esa entrevista. Para disipar el pesimismo sobre el futuro de esta tecnología, Mehdi explica a EFE que en su empresa es clave “ la responsabilidad de cómo se construye la IA ”. “ Tenemos un esqueleto de trabajo de IA responsable, tenemos principios que aplicamos a toda la tecnología antes de lanzarla. Principios como: ¿Nuestro enfoque es transparente? ¿Estamos protegiendo a los niños? ¿Somos inclusivos? ¿Incluimos a todas las personas del mundo en esta tecnología? ”, destaca Mehdi, que es hijo de una mexicana y un indio. Otro miedo de la IA es cómo afectará al trabajo y a profesiones como los profesores, los diseñadores o programadores, entre otras. Para Mehdi esta tecnología afectará a los distintos empleos de tres maneras: los hará más productivos -en este caso los empleados usarán distintas herramientas de inteligencia artificial para ser “ más rápidos y eficaces ”- creará trabajos nuevos -como empleos que se especialicen en escribir los mensajes que se le tienen que dar a la IA- y, en algunos casos, destruirá otros empleos. Los empleos llamados a desaparecer serán los más “automatizados”, lo que obligará a volver a capacitar a los afectados. Para apoyar estas predicciones, Mehdi usó el ejemplo de las calculadoras y de las hojas Excel y de cómo la gente pensó en su momento que ya no se iban a necesitar contadores, lo cual no se cumplió. Sin embargo, numerosos expertos comparan la tecnología y las funciones que ofrecen los chatbot de IA y sus efectos con lo sucedido durante la Revolución Industrial, y algunos -como el caso de Gary Marcus, autor de dos libros sobre la IA- han advertido sobre los efectos que las pérdidas de empleos van a tener en el tejido social. En febrero, Microsoft se metió en la carrera de los chatbots potenciados con IA con Bing, que combina la tecnología GPT-4 y DALL-E 2 de Open AI (creadores de ChatGPT y DALL-E) con el índice de búsqueda de resultados de Microsoft, pero al que solo se podía acceder por invitación o por lista de espera. Esta semana la empresa anunció que Bing, al que solo se puede acceder por el navegador Microsoft Edge, estará disponible para todo el mundo de manera gratuita. De momento no tiene publicidad, pero la idea de Microsoft es incorporarla. En los primeros 90 días de vida pública de esta herramienta, Bing participó en más de 500 millones de chats y Bing Image Creator generó más de 200 millones de imágenes, según la empresa. Los usuarios pueden calificar las respuestas que reciben y Mehdi señala que la media de valoraciones positivas en estos tres meses es del 70 %, siempre según sus datos. Una de las primeras quejas que recibió Microsoft es que en “conversaciones” largas con Bing algunos usuarios recibieron respuestas perturbadoras, por ello la empresa puso un límite de 6 preguntas y esta semana se extendió el límite a 20. “ Hemos podido arreglarlo e introducir mejoras para disminuir los chats problemáticos. Inicialmente, limitamos los chats porque sabemos que el chat puede perder su contexto si se alarga demasiado. Solo seis respuestas era muy restrictivo, la gente no estaba contenta porque no les ayudaba. Pero 20 es suficiente para permitir que la gran mayoría de las personas tengan una gran experiencia ”, recalca. A medida que se popularice la IA se irán descubriendo nuevos usos para esta tecnología, añade Mehdi: “ Nunca pensamos que la gente usaría Bing como un mecanismo de chat social. Pensamos que lo usarían principalmente para la búsqueda (de información). Pero hemos visto que la gente lo estaba usando para interacciones sociales ”.