La inteligencia artificial está siendo incorporada rápidamente por distintas plataformas tecnológicas como  Facebook ,  Discord ,  SoundCloud ,  motores de búsqueda  y entre otras. Estos grupos están usando a la IA como un aliada para cumplir con el objetivo de brindar una mejor experiencia a los usuarios mientras usan los servicios que ofrecen. No obstante, los ciberdelincuentes también la están usando a su favor, pero para sofisticar sus ataques. ¿Cómo los cibercriminales están utilizando la inteligencia artificial? Para responder tal interrogante, hemos conversado con dos especialistas en ciberseguridad:   José Fernández, director de Latinoamérica y el Caribe para Ingenieros de Preventa en Palo Alto Networks; y Fabio Assolini, director del Equipo de Investigación y Análisis para América Latina en Kaspersky. “ChatGPT puede representar una  amenaza potencial para la seguridad informática  en general, ya que puede usarse para generar spam, escribir programas maliciosos y mensajes de phishing sofisticados”,  afirma Assolini. En concreto, la tecnología de OpenAI “ puede brindar  consejos generales sobre piratería y actividades maliciosas , podría alentar a las personas malintencionadas a participar en comportamientos ilegales”,  detalla el experto. Así como un estudiante puede pedirle al chatbot que explique sobre un tema complejo de alguna materia académica, los criminales cibernéticos también pueden solicitar información que puede usarse para fines maliciosos. “A finales de 2022 comenzaron a usar ChatGPT para crear variantes de malware” ,  señala José Fernández. Incluso, uno de los actores explicó cómo se hace en un foro clandestino de hacking:  “La clave para conseguir que cree lo que quieres, es especificando qué debe hacer el programa y los pasos a seguir...”. Este tipo de malware impulsado por la IA es capaz de recopilar datos y observar el comportamiento del usuario, así explica Fernández. También añade que, este programa malicioso puede permanecer dentro de un sistema “ hasta que esté listo para lanzar otra fase de un ataque o enviar información que ha recopilado con un riesgo relativamente bajo de detección”. "La generación de código (mediante ChatGPT) puede ayudar a los actores de amenazas menos calificados a lanzar ataques cibernéticos sin esfuerzo"   José Fernández, director de Latino América y el Caribe para Ingenieros de Preventa de Palo Alto Networks. Tal como afirmó el experto Kaspersky líneas arriba, los ciberdelincuentes pueden usar a ChatGPT para escribir mensajes de phishing, una técnica que busca engañar a la víctima haciéndose pasar por alguien más. “ El principal problema con los correos electrónicos masivos de phishing es que no tienen buena pinta, con demasiado texto genérico que no se dirige directamente al destinatario”,  explica la compañía en su  web . Es cambio, los acatantes informáticos  “pueden usar algoritmos de aprendizaje automático para crear y enviar correos electrónicos de phishing  personalizados creíbles que son más difíciles de detectar  y bloquear para los sistemas de seguridad,  explica   Fernández. Otro ejemplo de ataque, es  la estafa a adultos mayores con voces generadas por la IA  donde los ancianos al  oír a sus seres queridos terminaron perdiendo miles de dólares. Asimismo, Assolini añade que otro de los tipos de IA muy utilizados son los  deepfake , “ una técnica que permite obtener vídeos o imágenes de personas que aparentemente son reales”. Basándose en un   estudio de Kaspersky , especialista señala que  “el 70% de los usuarios de internet ignora la existencia de esta táctica. De los encuestados, los peruanos (75%) son los que más la desconocen, seguidos de los mexicanos y chilenos (ambos con 72%)”. “Este índice de desconocimiento es preocupante porque podría garantizar el éxito de tácticas de ingeniería social y fraude que aplican esta tecnología”,  alerta   Assolini. El especialista asegura que se han reportado casos en los que los ciberdelincuentes han usado una voz falsa, haciéndose pasar por funcionarios de una empresa, para conseguir que dicha compañía les transfieran fondos. Ahora bien, ¿cómo podemos defendernos ante las tácticas sofisticadas de los ciberdelincuentes? En cuanto a un texto generado por una IA, Assolini nos aclara que es posible identificar cuando se trate de uno escrito por un chatbot. Esta  “tecnología  utiliza las combinaciones y frases más comunes del lenguaje  pero que, en sus comunicaciones,  no tiene una lógica de pensamiento o razonamiento . Muchas veces, pueden brindar información falsa o inexacta”. “En el caso de imágenes o videos, estos tienden a ser  de baja calidad  y pueden detectarse al notar  movimientos de labios poco naturales , cabello mal representado, formas de rostro que no coinciden,  parpadeo escaso o nulo , diferencias en el color de la piel”. Finalmente, sobre la interrogante de cómo actuarán los cibercriminales en un futuro, el especialista José Fernández revela que “ seguirán confiando en los últimos avances tecnológicos para aumentar su alcance y efectividad”  y que estos actores podrán usar con mayor frecuencia los “ códigos maliciosos sin conocimientos informáticos avanzados”  ya que solo deberán seguir los pasos que un delincuente pueda vender por Internet.