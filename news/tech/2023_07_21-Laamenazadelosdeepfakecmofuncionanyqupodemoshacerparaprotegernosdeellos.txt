La  inteligencia artificial  (IA) ha experimentado un crecimiento importante en este último año. Sobre todo, nos ha sorprendido su capacidad de aportar en diversos tipos de actividades. Por ello, desde estudiantes hasta científicos experimentan y hacen uso de esta herramienta. No obstante, quienes también la utilizan son personas malintencionadas para crear videos y fotos falsas, es decir, los deepfake. Como bien señaló hace un tiempo Brad Smith, el presidente de Microsoft, en una comparecencia ante legisladores de Estados Unidos, la mayor preocupación acerca de la IA es que ayuda a  la propagación de los deepfakes. “ Necesitamos tomar medidas para protegernos  contra la alteración de contenido legítimo con la intención de engañar o defraudar a las personas mediante el uso de IA ”, declaró. El nombre de deepfake viene de las palabras ‘ deep learning ’ (aprendizaje profundo) y  fake  (falso), señala Carlos Castillo García, gerente de marketing y comunicaciones de NTT Data para Perú y Ecuador. Se trata de una tecnología basada en i nteligencia artificial y técnicas de aprendizaje automático  que permiten crear imágenes, videos y audios falsos, pero que aparentan ser reales. “ Los deepfakes utilizan algoritmos de aprendizaje automático para aprender patrones y características de un grupo grande de datos , como fotografías o videos, para luego aplicarlos a otra persona o contexto ”, afirma en conversación con este Diario. En cuanto a su funcionamiento, el especialista explica que tiene un proceso que consiste en varias etapas, que pueden ser resumidas, principalmente, en dos. Alimentación de información : el algoritmo analiza y aprende toda la data de la persona que va a imitar como sus rasgos faciales, expresiones y movimientos. Generación : una vez entrenado con la información, el algoritmo aplica lo aprendido en un contenido original, modificándolo para que parezca que se trata de algo real. Los deepfakes tienen diferentes usos que se pueden agrupar en dos: para fines de entretenimiento o sin perjuicio, pero también con  objetivos malintencionados . “ Es decir, pueden emplearse en la industria del entretenimiento para efectos visuales y mejoras en la postproducción. Sin embargo, también pueden ser utilizados para crear  contenido engañoso, como noticias falsas o difamación ”, explica Castillo. En concreto, el uso negativo de este tipo de herramienta tecnológica puede conllevar consecuencias “ graves ”, así es como lo califica el especialista. “ Puede llevar a  engañar a las personas  haciéndoles creer cosas que en realidad no ocurrieron o que fueron dichas por alguien que nunca las dijo ”, señala. En este sentido, los deepfake pueden contribuir en la  desinformación, manipulación de la opinión pública, suplantación de identidad y difamación . Asimismo, “ a nivel de sociedad existe el riesgo de que creando contenido falso que apoya una determinada agenda o manipula la percepción pública sobre un tema en particular, se puede  afectar la confianza en las instituciones ”, sostiene el especialista de NTT Data. Ahora bien, recientemente una nueva forma de hacer uso de los deepfake ha sido advertido por el FBI. Se trata de la  sextorsión, una modalidad delictiva que usa contenidos sexuales  para pedir dinero a las víctimas, si no, las amenazan con publicar y hacer viral las  imágenes falsas impulsadas por IA . “ El FBI continúa recibiendo informes de víctimas, incluidos niños menores y adultos que no dieron su consentimiento, cuyas fotos o videos fueron alterados en contenido explícito. Luego, las fotos o videos se  distribuyen públicamente en las redes sociales o sitios web pornográficos , con el fin de acosar a las víctimas o esquemas de sextorsión ”, informa la agencia. Como sostiene Rodrigo Ochoa, líder de automatización e Inteligencia artificial de Moventi, el nivel de dificultad para detectar un deepfake va a depender del nivel y calidad con que se haya desarrollado el algoritmo. Por ello, para poder reconocer si un contenido es real o falso, es  necesario prestar mucha atención a los detalles y apelar al sentido común , ya que podemos estar frente a un contenido aparentemente convincente. “Con la tecnología dando saltos grandes, cada vez más va a ser más complicado que un usuario promedio tenga la habilidad de poder discernir entre qué es real y qué es un deepfake” Rodrigo Ochoa   Líder de automatización e inteligencia artificial de Moventi Pese a ello, Carlos Castillo nos da los siguientes alcances: Los deepfakes a veces pueden mostrar  imperfecciones o anomalías en la cara , como  movimientos poco naturales de los ojos, boca o cejas . Pueden tener una  calidad visual inferior  en comparación con el material original. Presentan una  falta de sincronización precisa entre los labios y el audio . Ochoa añade que la verificación del contenido también es importante. El usuario debe de  analizar en qué contexto sale el video falso, analizar de dónde viene y por qué . A modo de ejemplo, en la esfera política, los deepfake pueden ser usados como arma para desacreditar a los opositores. Un caso en concreto fue en 2021, cuando varios políticos europeos fueron engañados durante una videollamada por un deepfake que imitaba a un opositor ruso. Cómo informó  Xataka , los afectados explicaron que “ todo era una trampa para dejarles en mal lugar ”. Por otro lado,  ¿cómo protegerse de la sextorsión? , los expertos Castillo y Ochoa coinciden en los siguientes puntos: Protege tu identidad . Si tienes tus perfiles en las redes sociales, ponlos en privado. Sé cauteloso con las solicitudes de amistad o seguidores . Si te agregan nuevas personas, averigua quiénes son. No compartas contenido personal sensible o confidencial . Recuerda que los videos o imágenes que publicas, son de acceso gratis que un usuario puede tener. Asimismo, los expertos sugieren para evitar ataques y vulnerabilidades, mantener los dispositivos móviles  actualizados con las últimas versiones de software , así como contar con  sistemas de antivirus  en los ordenadores. “Muchas personas le tienen miedo a la inteligencia artificial por el mal uso que se le puede dar en algunos casos.  La IA es una herramienta más, por cómo la usemos, eso no es culpa de ella.  Siempre va ser difícil comprometer a todos a hacer un uso ético de esta herramienta”,  finaliza el especialista de Moventi en entrevista con  El Comercio .