La convivencia actual entre las tensiones geopolíticas y el auge de las tecnologías emergentes hace de este un momento histórico en el que el debate por la seguridad, incluso más allá de nuestro planeta, se vuelve trascendental. Mallory Stewart, secretaria adjunta para Control, Verificación y Cumplimiento de Armas (AVC) del Departamento de Estado de  Estados Unidos , sostiene que el entorno de seguridad internacional es cada vez más desafiante, mientras que en el entorno político multilateral se abandonan tratados y otras arquitecturas adoptadas para evitar una escalada involuntaria, malentendidos y errores de cálculo con consecuencias que lamentar. Tras visitar Brasil, la funcionaria llegó esta semana a Lima, donde se reunió con autoridades peruanas y participó en una mesa de diálogo con El Comercio y otros dos medios locales sobre seguridad espacial e inteligencia artificial. — La exploración espacial atraviesa una nueva era. Aunque no tiene un gran programa espacial, ¿cómo podría el Perú, u otros países latinoamericanos, beneficiarse de los esfuerzos de EE.UU. en ese campo y cuáles son los pasos a seguir? ¿Cómo podemos integrar a la región? Creo que es un momento muy emocionante. Gran parte de lo que hemos estado haciendo en el Gobierno de EE.UU. es tratar de recoger las lecciones aprendidas. Nuestros esfuerzos en el espacio y en la tecnología emergente a veces van hacia adelante lo más rápido posible, pero no siempre nos sentamos y nos preguntamos qué podríamos haber hecho mejor. Creo que el espacio es un buen ejemplo de cómo nos hemos dado cuenta, tras varias décadas de utilización del espacio, del reto que suponen los desechos espaciales. Y, aunque en el pasado hemos creado desechos, ahora nos hemos dado cuenta de lo difícil que es manejarlos. Así que, desde nuestro punto de vista, es mejor trabajar con los países que se están desarrollando e introduciendo en el ámbito espacial de forma más completa. Ahora intentamos ayudar al Perú a entender cuáles son las cuestiones y los retos a los que se enfrentan, pero también queremos compartir las lecciones aprendidas para que sepamos que es importante comprometemos a no crear más desechos que hacen que las operaciones espaciales se vuelvan más complicadas. Ahora mismo estamos entrando en este momento realmente emocionante en el que nuestra cooperación ampliada está creciendo de forma fabulosa. — ¿Cómo evalúa la participación del Perú? Es un momento positivo para empezar a decir que apreciamos profundamente el compromiso del Perú con el comportamiento responsable que vimos en la Asamblea General de la ONU, en el 2022, cuando se aprobó una resolución para evitar que se produzca más basura espacial. Debemos trabajar en lo que podemos hacer para prevenir cualquier tipo de desafío para nuestro uso colectivo e integral del espacio en el futuro. El enfoque basado en las lecciones aprendidas y en aprender del Perú sobre los retos a los que nos enfrentamos es realmente apasionante. PERFIL Mallory Stewart En el cargo desde: 18/4/2022 Profesión: Abogada Trayectoria: Antes de asumir su posición actual, sirvió como asistente especial del presidente Joe Biden y fue directora principal de Control de Armas en el Consejo de Seguridad Nacional. — ¿De qué manera puede utilizarse la Inteligencia Artificial (IA) para explicar el espacio? Creo que hay que tratar de enfocar el entorno espacial desde la perspectiva de la utilidad para todos los países y la sostenibilidad del apasionante potencial que nos ofrece ahora, pero también para las generaciones futuras. Por lo tanto, debemos utilizar nuestra capacidad para trabajar juntos y explorar nuevos accesos en los lugares que necesitan una mayor representación en la comunidad espacial. Esto nos ayudará a ampliar tanto la capacidad de entender a dónde tenemos que ir, lo que tenemos que lograr y tal vez cómo podemos utilizarlo mejor como una comunidad global. Uno de los retos a los que se han enfrentado los operadores espaciales es la limitada comunidad a la que pertenecen y creo que hay que ampliar esa comunidad para ver cómo los nuevos actores espaciales, como el Perú y otros países de la región, pueden aportar su experiencia y conocimientos para lograr mayores capacidades de exploración espacial. No es momento de limitarse a una conversación entre unos pocos países, sino de ampliarla realmente a lo que tiene que ser, que es una conversación global. "Uno de los retos a los que se han enfrentado los operadores espaciales es la limitada comunidad a la que pertenecen". — ¿Cuán avanzado está el uso militar de la IA? ¿Ve riesgos significativos? ¿Tal vez algo que involucre a América Latina? En EE.UU. todavía estamos tratando de entender lo avanzado que está nuestro propio uso de la inteligencia artificial en nuestro Ejército, pero también dónde están los buenos usos y beneficios potenciales, que ya son bastante amplios. Me sorprende lo omnipresente que es el uso de la IA en nuestros iPhones, en nuestras computadoras, incluso en el funcionamiento de aparatos de cocina mundanos. En EE.UU., la IA se ha utilizado en nuestro Ejército. Nuestra preocupación desde la Oficina de Control de Armas se centra especialmente en los riesgos que el uso de la IA podría tener en el contexto militar si no hay una formación adecuada, una comprensión adecuada de los riesgos potenciales y de los desafíos que el sesgo involuntario podría traer a un sistema de inteligencia artificial, especialmente los riesgos de no incluir a un humano en la toma de decisiones estratégicas cruciales. Nuestro Departamento de Defensa tiene una amplia supervisión y requisitos de gestión ética que ya han puesto en marcha y que se reflejan en gran medida en la declaración militar sobre el uso de la IA en el espacio militar que la subsecretaria de nuestra oficina, Bonnie Jenkins, presentó en febrero del 2023. Esa declaración representa lo que nuestro Ejército ha aprendido de algunos de sus esfuerzos para utilizar la IA de forma responsable. Pero la declaración está evolucionando y estamos hablando con el Gobierno Peruano y otros gobiernos de la región para escuchar cómo se puede maximizar la utilidad de la IA de una manera positiva y cómo podemos utilizar este tipo de compromisos y regulaciones para prevenir los riesgos que la IA puede traer. — ¿Cómo se pueden prevenir esos riesgos? Hemos vuelto a un análisis del tipo “lecciones aprendidas”. Hemos visto que se nos escapó la incorporación de sesgos y errores humanos en anteriores sistemas de IA. Es algo que descubrimos a posteriori y que queremos tratar de evitar a medida que la IA se utilice más y más en el futuro. Así que, para garantizar un contexto de formación adecuado para la comprensión de esta tecnología, se debe evitar que en el contexto militar un error pueda continuar sin el conocimiento humano y garantizar que siempre haya un ser humano en el bucle en la toma de decisiones estratégicas, lo que es una de las cosas más importantes desde una perspectiva de control de armas. Nunca hay una decisión tomada con respecto a las armas estratégicas que no incluya la participación humana, que no incluya la supervisión, el conocimiento y la preocupación extrema y la perspicacia de un humano. "Se debe evitar que en el contexto militar un error pueda continuar sin el conocimiento humano y garantizar que siempre haya un ser humano en el bucle en la toma de decisiones estratégicas". — ¿Qué es lo que más le preocupa a Estados Unidos en materia de seguridad en América Latina? No es necesariamente mi área de especialización, pero sí puedo decir que no se trata de América Latina en concreto. Yo diría que a medida que vemos cómo las tecnologías emergentes y los ámbitos de seguridad emergentes se expanden y se vuelven extraordinariamente complicados, tenemos preocupaciones de seguridad para nosotros mismos, pero también para nuestros socios. Y la concienciación es una gran parte de lo que hacemos en la Oficina de Control de Armas para intentar que todo el mundo sea consciente de los riesgos potenciales, de modo que podamos trabajar juntos de forma global no sólo para disuadir esos riesgos, sino también para intentar prevenirlos a través de la supervisión y la regulación y los comportamientos responsables. “Tenemos más preocupaciones de seguridad para nosotros mismos, pero también para nuestros socios”. — En cuanto a la relación entre la IA y la ciberseguridad, no tenemos que tener un gran presupuesto para generar riesgos y se puede hacer desde cualquier país, incluido el Perú. ¿Cómo ve este escenario? Es una conversación muy importante y muy complicada. Creo que la capacidad de IA para exacerbar algunos de los retos de ciberseguridad, para encontrar cosas que ni siquiera un investigador humano podría encontrar en términos de agujeros en las protecciones de trabajo de seguridad, es algo que a todos no nos deja dormir. Es algo que se ve potencialmente en las películas de Hollywood, pero es una preocupación real y creo que es una de las razones por las que realmente necesitamos comportamientos responsables en la apreciación de cómo la IA puede convertirse en parte de todo lo que hacemos. Muchas personas, oficinas y agencias lo están estudiando en EE.UU. y sé que es algo que el Gobierno Peruano también está estudiando activamente. La Oficina de Ciberseguridad se acaba de crear en el Departamento de Estado. En EE.UU. contamos con un asesor principal del Secretario de Estado en materia de seguridad y tecnología y en el Consejo de Seguridad Nacional de la Casa Blanca. También hemos desarrollado capacidades y conocimientos adicionales sobre cómo el reto de la seguridad va a afectarnos a todos. Pero también se trata del uso responsable de la IA. Tenemos que ser capaces de entender cómo los países pueden regular los contextos, conocimientos y usos reales de la IA podría ayudar a prevenir su uso nefasto en el escenario de la ciberseguridad. Es una cuestión realmente complicada, pero es una buena pregunta, y me alegro de que todos estemos pensando en ello, porque la ciberseguridad es un área que nos afecta a todos y no requiere una gran cantidad de recursos para realizar un uso realmente nefasto de ella. Ser responsables, concienciarnos de los retos que plantea e intentar trabajar juntos para prevenir sus riesgos y su eficacia es algo en lo que todos deberíamos trabajar.