Los avances tecnológicos en los drones usados en  Ucrania  han acelerado una tendencia que pronto podría llevar al campo de batalla a los primeros robots de combate totalmente autónomos, inaugurando una nueva era en las guerras. Cuanto más dure la guerra, más probable será que se utilicen drones para identificar, seleccionar y atacar objetivos sin ayuda humana, según analistas militares, combatientes e investigadores de inteligencia artificial. Eso supondría una revolución en la tecnología militar tan profunda como la introducción de la ametralladora. Ucrania ya dispone de drones de ataque semiautónomos y de armas contra drones dotadas de inteligencia artificial. Rusia también afirma poseer armamento con IA, aunque tales afirmaciones no están probadas. Pero no hay casos confirmados de que una nación haya puesto en combate robots que hayan matado humanos con completa autonomía. Los expertos afirman que puede ser sólo cuestión de tiempo que Rusia o Ucrania, o ambas, los desplieguen. La sensación de inevitabilidad se extiende a los activistas, que llevan años intentando prohibir los drones asesinos, pero ahora creen que deben conformarse con intentar restringir el uso ofensivo de estas armas. El ministro ucraniano de Transformación Digital, Mykhailo Fedorov, está de acuerdo en que los drones letales totalmente autónomos son el “siguiente paso lógico e inevitable” en el desarrollo de armas. Dijo que Ucrania ha estado haciendo “mucha investigación y desarrollo en esta dirección”. “Creo que el potencial para ello es grande en los próximos seis meses”, declaró Fedorov a The Associated Press en una entrevista reciente. El teniente coronel ucraniano Yaroslav Honchar, cofundador de la empresa de innovación en drones de combate sin ánimo de lucro Aerorozvidka, afirmó en una entrevista reciente cerca del frente de batalla que los combatientes humanos simplemente no pueden procesar la información y tomar decisiones tan rápidamente como las máquinas. Los líderes militares ucranianos prohíben actualmente el uso de armas letales totalmente independientes, aunque eso podría cambiar, dijo. “Todavía no hemos cruzado esta línea, y digo ‘todavía’ porque no sé qué ocurrirá en el futuro”, afirmó Honchar, cuyo grupo ha encabezado la innovación en el campo de los drones en Ucrania, convirtiendo drones comerciales baratos en armas letales. Rusia podría obtener IA autónoma de Irán o de otros países. Los drones explosivos de largo alcance Shahed-136 suministrados por Irán han dañado centrales eléctricas ucranianas y aterrorizado a civiles, pero no son especialmente inteligentes. Irán tiene otros drones en su arsenal que, según dice, incorporan IA. Sin mucho problema, Ucrania podría hacer que sus drones semiautónomos fueran totalmente independientes para sobrevivir mejor a la interferencia electrónica en el campo de batalla, de acuerdo con los fabricantes de Occidente. Entre esos drones se encuentran el Switchblade 600, de fabricación estadounidense, y el Warmate, de fabricación polaca, que actualmente requieren que un humano elija los objetivos a través de una señal de video en directo. La IA termina el trabajo. Los drones, técnicamente conocidos como “municiones merodeadora”, pueden cernirse durante varios minutos sobre un objetivo, a la espera de un disparo limpio. “La tecnología para lograr una misión totalmente autónoma con Switchblade ya existe”, afirma Wahid Nawabi, director general de AeroVironment, su fabricante. Para ello será necesario un cambio de política —eliminar al ser humano del circuito de toma de decisiones— algo que, según sus cálculos, está a tres años de distancia. Los drones ya pueden reconocer objetivos, como vehículos blindados, mediante imágenes catalogadas. Pero hay desacuerdos sobre si la tecnología es lo suficientemente fiable como para garantizar que las máquinas no se equivoquen y acaben con la vida de no combatientes. La AP preguntó a los ministerios de Defensa de Ucrania y Rusia si habían utilizado armas autónomas con fines ofensivos y si se comprometerían a no utilizarlas si la otra parte también lo hiciera. Ninguno de los dos respondió. Si uno de los dos bandos pasara al ataque con una IA completa, ni siquiera sería la primera vez. Un informe no concluyente de la ONU indica que los sistemas letales autónomos (o “robots asesinos”) debutaron en el conflicto interno de Libia en 2020, cuando drones Kargu-2 de fabricación turca en modo totalmente automático mataron a un número indeterminado de combatientes. Un portavoz de STM, el fabricante, dijo que el informe se basaba en información “especulativa y no verificada” y que “no debe tomarse en serio”. Indicó a la AP que el Kargu-2 no puede atacar un objetivo hasta que el operador se lo ordena. Honchar cree que Rusia, cuyos ataques contra civiles ucranianos han mostrado poca consideración por el derecho internacional, ya habría utilizado drones autónomos si dispusiera de ellos. “No creo que tuvieran escrúpulos”, coincidió Adam Bartosiewicz, vicepresidente de WB Group, fabricante del Warmate. La IA es una prioridad para Rusia. El presidente Vladimir Putin dijo en 2017 que quien domine esa tecnología dominará el mundo. En un discurso pronunciado el 21 de diciembre, expresó su confianza en la capacidad de la industria armamentista rusa para añadir IA a las máquinas de guerra, subrayando que “los sistemas de armas más eficaces son los que funcionan rápida y prácticamente en modo automático.” Los funcionarios rusos ya afirman que su dron Lancet puede operar con total autonomía. Hasta ahora, los intentos de establecer unas normas básicas internacionales para los drones militares han sido infructuosos. Nueve años de conversaciones informales de las Naciones Unidas en Ginebra apenas han logrado avances, y las principales potencias, entre ellas Estados Unidos y Rusia, se oponen a una moratoria. La última sesión, celebrada en diciembre, concluyó sin que se hubiera programado una nueva ronda. Toby Walsh, académico australiano que hace campaña contra los robots asesinos, espera lograr un consenso sobre algunos límites, incluida la prohibición de sistemas que utilicen el reconocimiento facial y otros datos para identificar o atacar a individuos o categorías de personas. “Si no tenemos cuidado, van a proliferar mucho más fácilmente que las armas nucleares”, indicó Walsh, autor de “Machines Behaving Badly” (Máquinas portándose mal). “Si puedes hacer que un robot mate a una persona, puedes hacer que mate a 1.000″. Varios países y todas las ramas del ejército estadounidense están desarrollando drones capaces de atacar en mortíferos enjambres sincronizados, señaló Zachary Kallenborn, analista de innovación armamentista de la Universidad George Mason. ¿Se convertirán las guerras futuras en una lucha hasta el último dron? Eso es lo que predijo Putin en una charla televisada en 2017 con estudiantes de ingeniería: “Cuando los drones de una parte sean destruidos por los drones de la otra, no tendrá más remedio que rendirse”.