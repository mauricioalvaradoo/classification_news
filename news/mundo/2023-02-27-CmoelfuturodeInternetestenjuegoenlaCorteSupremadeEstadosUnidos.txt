Nohemi González, una estadounidense de 23 años de origen mexicano, fue asesinada en París en los atentados del 13 de noviembre del 2015 del grupo terrorista  Estado Islámico , donde en total murieron 130 personas. El jordano Nawras Alassaf murió el 1 de enero del 2017 en un club nocturno en Estambul (Turquía) a manos de Abdulkadir Masharipov, un terrorista que irrumpió en el lugar y asesinó a 39 personas. Ambos casos han llegado a la Corte Suprema de  Estados Unidos  y podrían definir el futuro de la  Internet . ¿Pero qué tiene que ver Internet con los atentados terroristas antes mencionados? La semana pasada, los jueces de la Corte Suprema de Estados Unidos escucharon los argumentos de las demandas de la  familia González contra   Google  por su plataforma de videos  YouTube  y de la  familia de Alassaf contra Twitter . Las querellas buscan que se determine la responsabilidad de estas empresas tecnológicas sobre el contenido que los usuarios publican en sus plataformas. De acuerdo con Telemundo, los denunciantes  cuestionan el alcance de la sección 230 de la   Ley de Decencia en las Comunicaciones , adoptada en 1996, que da poder a las empresas tecnológicas para moderar el contenido de los internautas, pero  las protege de ser demandadas por lo que estos publican. El caso de Nohemi González Nohemi González  era estudiante de la Universidad Estatal de California y en el 2015 estaba pasando un semestre en París estudiando diseño industrial. Ella fue asesinada en la cafetería la Belle Equipe de la capital de Francia por un comando del grupo yihadista Estado Islámico. Sus padres  acusan a YouTube de haber recomendado videos del grupo yihadista a algunos de sus usuarios. Según la demanda, “al recomendar videos del  Estado Islámico  a sus usuarios,  Google   ha ayudado al Estado Islámico a difundir su mensaje  y, por lo tanto, le ha brindado apoyo material”. “El problema es que cuando haces clic en un video,  YouTube  te seguirá enviando automáticamente otros videos que no has solicitado”, dijo el abogado Eric Schnapper, en nombre de la familia  González . Pero según Lisa Blatt, representante de Google, el término de “recomendación” es excesivo.  “Hay 3.500 millones de consultas diarias en el motor de búsqueda. (Las respuestas) son diferentes para cada persona y podrían todas ser consideradas como recomendaciones”,  afirmó. Aseguró que “Internet jamás habría despegado si todo el mundo pudiese demandar todo el tiempo”. Antes de que el caso llegara a la Corte Suprema, los tribunales inferiores dieron la razón a  Google  en nombre de la disposición legal conocida como sección 230, adoptada cuando Internet estaba en sus inicios y que se ha convertido en uno de sus pilares. De acuerdo con la agencia AFP,  esta sección decreta que las empresas de Internet gozan de inmunidad legal por el contenido que publican porque no son un “editor”. El caso de Nawras Alassaf Los familiares de  Nawras Alassaf  acusan a  Twitter  de complicidad con el  Estado Islámico , que reivindicó la autoría del atentado del 1 de enero de 2017 en el que murieron él y otras 38 personas durante una celebración de Año Nuevo, debido a que la plataforma no vigiló las cuentas o publicaciones del grupo terrorista. Según los denunciantes, si la organización terrorista utiliza plataformas como Twitter  “para reclutar miembros, emitir amenazas terroristas, difundir propaganda, infundir miedo e intimidar a la población civil”, las compañías tecnológicas fueron responsables de instigar el atentado en el que murió Alassaf. Agregan que Twitter brindó apoyo material al Estado Islámico al proporcionar la infraestructura y los servicios que le permiten  “promover y llevar a cabo sus actividades terroristas”, al no monitorear y eliminar de manera proactiva el contenido terrorista. OPINIÓN Hay un débil compromiso de las empresas para mejorar lo que sucede en sus redes sociales Por Manuel Santillán,  doctor por la European University Viadrina de Alemania y  docente de la Universidad de Lima En términos generales, hay una preocupación no solo de la Unión Europea sino también del Congreso de Estados Unidos para ver  cómo exigir a las empresas de tecnología que sean más cuidadosas  con la privacidad de las personas por un lado y con lo que ellas permiten que aparezca en sus plataformas por el otro.  Las empresas de tecnología dicen que  ellos no quieren ser filtros , no quieren asumir esa responsabilidad porque, además, eso significa el empleo de grandes recursos humanos. Incluso hay  una exempleada de Facebook que declaró que las empresas de tecnología en realidad no están muy interesadas en aplicar filtros rigurosos porque verían mermados sus ingresos .  Así, por un lado vemos las demandas hacia las empresas para que busquen revisar los contenidos y a la vez respetar los derechos de los usuarios, y por otro lado las mismas empresas de tecnología, que sí saben de problema,  tienen un débil compromiso en procurar que en algo mejore lo que está sucediendo en sus redes sociales .  Hay mucho contenido terrorista, otros que afectan derechos de las personas, también los que incitan al odio, hay contenido extremista, peligroso, hay muchas agrupaciones de extremos políticos, teorías conspirativas, noticias falsas, todo eso es un problema que no tiene solución. Es un tema muy delicado que todavía se está discutiendo. No se encuentra una fórmula para ver qué hacer. Mientras tanto, las cosas siguen evolucionando, ahora ya tenemos inteligencia artificial, pero  estos avances tecnológicos van más rápido que la implementación de nuevas regulaciones. En manos de la Corte Suprema Como lo anota la agencia EFE, la Corte Suprema de Estados Unidos tendrá que  dirimir si, según la Ley Antiterrorista, se puede considerar que las plataformas de redes sociales que alojan contenido de usuarios han ayudado e instigado un acto de terrorismo internacional por su supuesta falla a la hora de filtrar y eliminar el contenido publicado por organizaciones terroristas. CNN  remarca que las empresas tecnológicas grandes y pequeñas están siguiendo el caso, temerosas de que los jueces puedan cambiar la forma en que los sitios recomiendan y moderar el contenido en el futuro y hacer que los sitios web sean vulnerables a docenas de demandas, amenazando su propia existencia. La agencia AFP recuerda que en el pasado, varios jueces de la Corte Suprema han expresado su deseo de cambiar la lectura del artículo 230, que los políticos cuestionan cada vez más, aunque las divisiones entre demócratas y republicanos obstaculizan que se pueda modificar. Y por lo escuchado en la misma corte la semana pasada, no hay señales claras de lo que pretende hacer la máxima instancia de la justicia de Estados Unidos. “Si nos ponemos de su lado, de pronto Google dejará de estar protegido. Y quizá es lo que quiere el Congreso, pero ¿no es algo que debe decidir el Congreso y no el tribunal?”, preguntó la semana pasada la jueza  Elena Kagan . Cambiar la ley podría “hacer que se derrumbe la economía digital, con todo tipo de consecuencias para los trabajadores y los fondos de pensiones, etc”, sostuvo el juez John Roberts. En la vista del miércoles, el abogado de Twitter, Seth Waxman, centró su defensa en que no hacer todo lo posible para hacer cumplir las reglas y políticas de Twitter que prohíben este tipo de contenido “no equivale a la provisión consciente de asistencia sustancial” a los proveedores de los contenidos violentos. “Si el jefe de policía de Estambul hubiera venido a Twitter diciendo ‘hemos estado siguiendo tres cuentas y estas personas parecen estar planeando algún tipo de acto terrorista’ y Twitter no lo hubiera investigado, en ese caso habríamos asumido la culpabilidad”, r elató, de acuerdo con EFE. Twitter  asegura que el hecho de que el  Estado Islámico  haya utilizado la plataforma no constituye una asistencia “consciente”, una postura que comparte la Administración de  Joe Biden . EFE también recordó que según el procurador general adjunto Edwin Kneedler, representante del Gobierno de EE.UU.,  Twitter no puede ser considerada responsable en virtud de la Ley Antiterrorista porque el Congreso se aseguró de que esta ley “no tenga un alcance tan amplio como para inhibir actividades legítimas e importantes de empresas, organizaciones benéficas y otros”. Pero en opinión de varios de los jueces de la Corte Suprema como Elena Kagan, Twitter “sabía todo eso y no hizo nada al respecto”. “¿Cómo se puede decir que Twitter no brindó asistencia sustancial?”, preguntó la jueza, quien aseguró que la red social “está ayudando al brindar servicio a aquellas personas con el conocimiento explícito de que esas personas lo están utilizando para promover el terrorismo”. En opinión del abogado Keith Altman, “es fundamental” que la Corte Suprema analice los dos casos y que “trate de brindar alguna orientación”. “Se trata de pedirles a las empresas que actúen de manera razonable y responsable en la forma en que administran su contenido y no simplemente decir, bueno, no hay nada que puedan hacer al respecto”, apuntó. Importante  El tribunal dictará sentencia para ambos casos antes del 30 de junio.