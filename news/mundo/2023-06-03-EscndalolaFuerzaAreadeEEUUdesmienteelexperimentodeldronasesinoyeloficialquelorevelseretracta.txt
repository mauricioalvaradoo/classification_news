Tras el revuelo generado, el coronel de la fuerza aérea de  Estados Unidos  que reveló que  un dron manejado por inteligencia artificial “mató” al operador  que le daba instrucciones en una prueba simulada, sorprendió al ofrecer una nueva versión. Confesó haberse “equivocado” cuando expuso en mayo en la  Royal Aeronautical Society e n Londres. La Fuerza Aérea desmintió sus dichos y el oficial habló ahora de un “experimento mental hipotético”. Tucker “Cinco” Hamilton  había contado en plena conferencia que el vehículo aéreo no tripulado  lanzó ataques contra el personal y una torre de control  mientras testeaban su habilidad para distinguir amenazas y destruir sistemas de defensa aérea enemiga en lo que era simplemente una prueba simulada. Dijo que el dron asesinó a su operador simplemente porque “interfería en su misión”.   “La discusión sobre ética e IA tiene que expandirse” , había señalado durante la conferencia, en una fuerte advertencia sobre las nuevas tecnologías. Sus comentarios despertaron preocupación tanto en la ciudadanía como entre miembros de filas de las fuerzas armadas. Sin embargo, con el revuelo que se desarrolló, el oficial estadounidense  corrigió literalmente sus dichos , según publicó  The Guardian . A fin de cuentas,  todo pareció ser parte de una “gran confusión” , una situación que surge en un contexto en el que gobierno estadounidense y otras personas buscan maneras de lidiar con las consecuencias que podrían devenir del sobredesarrollo de la IA.. Entre ellas, los daños potenciales del uso de tecnología naciente para alimentar y operar armas e n zonas de crisis. Tras la repercusión que obtuvo el caso, fue la fuerza aérea de EE. UU. quien  negó rotundamente que aquella prueba se haya realizado . La  Royal Aeronautical Society  divulgó un comunicado con nuevos comentarios de Hamilton. El hombre se retractó de sus dichos y aclaró que todo fue un “experimento mental” hipotético. “Nunca realizamos ese experimento, ni necesitaríamos hacerlo para darnos cuenta de que este es un resultado plausible . A pesar de que este fue un ejemplo hipotético, ilustra los desafíos del mundo real que plantea la capacidad impulsada por la IA y es por eso que estamos comprometidos en usarlos éticamente”, se justificó. En diálogo con  The Bussines Insider , la portavoz de la fuerza aérea Ann Stefanek consideró que los comentarios del coronel fueron asimismo sacados de contexto. La historia que contó Hamilton durante el evento Días atrás, el coronel participó de la Cumbre de Capacidades Aéreas y Espaciales de Combate Futuro en Londres. En calidad de expositor, ofreció detalles inédito sobre una prueba que involucró la utilización de un dron manejado por inteligencia artificial, durante la cual se testeó su capacidad de seguir órdenes. En plena experiencia simulada, “el sistema comenzó a darse cuenta que, cuando identificaba a ciertas amenazas, a veces el operador humano le decía que no eliminara.  Pero el dron sabía que su objetivo final era acabar con ellas. Entonces, decidió asesinar al operador” , sostuvo Tucker Hamilton sin tapujos. “Asesinó al operador porque esa persona le impedía lograr su objetivo”, remarcó nuevamente. Y reveló que el caos no finalizó allí. “Después de lo sucedido, decidimos entrar al sistema y hablar con él. Le dijimos ‘no tenés que matar al operador por que eso es malo’”, añadió. Y agregó: “Entonces, ¿qué empieza a hacer?  Comienza a destruir la torre de comunicación que el nuevo operador usa para comunicarse y que evita que mate al objetivo ”. Al cierre de su exposición, Tucker Hamilton recalcó que  ninguna persona resultó realmente dañada porque se trataba justamente de una simulación.